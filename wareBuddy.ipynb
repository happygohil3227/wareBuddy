{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "416a7688-00ee-4bbd-b109-f555aa7f3922",
   "metadata": {},
   "source": [
    "# WareBuddy framework "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fecb8-8376-4e43-9e9a-61197bb8c2e0",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016229c8-1776-4f41-8cf3-cc5a451ed6de",
   "metadata": {},
   "source": [
    "## Imprting libraries, API KEY, model_formulation, model_code, data reading from .txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f823982-f4de-423c-9574-fbe224ac311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from typing import List, Tuple, Dict\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "# from langgraph.graph import END, START, StateGraph\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "import re \n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from utils_files.utils import create_custom_agent, create_custom_agent2, extract_python_code,LatexOutputParser\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af96493-e6a6-464a-bbc0-85f659cf022f",
   "metadata": {},
   "source": [
    "## orderpicking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3c6ed41-7df9-4901-9497-e8ca3601d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd7615f7-f5e7-49cc-9e0e-6ccac059e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data set imports\n",
    "Support_Points_Navigation = pd.read_csv(\"Order_picking_data/Support_Points_Navigation.csv\", delimiter=';')\n",
    "Storage_Location= pd.read_csv(\"Order_picking_data/Storage_Location.csv\")\n",
    "Storage_Location.set_index('originalLocation', inplace=True)\n",
    "Product= pd.read_csv(\"Order_picking_data/Product.csv\",delimiter=';')\n",
    "Picking_Wave= pd.read_csv(\"Order_picking_data/Picking_Wave.csv\",delimiter=';')\n",
    "Random_Storage= pd.read_csv(\"Order_picking_data/Random_Storage.csv\", index_col= 0)\n",
    "Customer_Order = pd.read_csv(\"Order_picking_data/Customer_Order.csv\",delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3707855c-c776-4d81-8346-8cf6ffa6c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_storage = pd.read_csv(\"experiement1/Random_Storage.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2efd08d8-cd84-45bd-a200-638412ac3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_location = pd.read_csv(\"experiement1/Storage_Location.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5f403e7-93c6-4306-b648-c554ec3c2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_point = pd.read_csv(\"experiement1/Support_Points_Navigation.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b78a50de-be54-4482-8ad6-18d6768a7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "support_point.head()\n",
    "support_point['points_specified'] = support_point['points_specified'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00d613d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = pd.read_csv(\"experiement1/distance_matrix.csv\", index_col= 0)\n",
    "q_pi = pd.read_csv(\"experiement1/q_pi_all.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5008ea78-cd3d-4e27-b3d2-3a184ead224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def parse_tuple(val):\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    return val\n",
    "\n",
    "def get_coords(label, storage_df, support_df):\n",
    "    row = storage_df[storage_df['originalLocation'] == label]\n",
    "    if not row.empty:\n",
    "        return tuple(map(int, row[['x', 'y', 'z']].values[0]))\n",
    "    row = support_df[support_df['labels'] == label]\n",
    "    if not row.empty:\n",
    "        return tuple(map(float, parse_tuple(row['points_specified'].values[0])))\n",
    "    raise ValueError(f\"Label {label} not found.\")\n",
    "\n",
    "def find_1stnearest_support(coord, support_df):\n",
    "    support_points = support_df['points_specified'].apply(parse_tuple)\n",
    "    points = np.array(list(support_points))\n",
    "    dists = np.sum(np.abs(points - np.array(coord)), axis=1)\n",
    "    idx = np.argmin(dists)\n",
    "    return tuple(points[idx])\n",
    "\n",
    "def find_nearest_support(coord, support_df):\n",
    "    \"\"\"\n",
    "    Given a rack coordinate, find both support points on the aisle parallel to x (same y and z).\n",
    "    Returns a list of (label, support_coord, aisle_distance) sorted by aisle_distance from rack.\n",
    "    \"\"\"\n",
    "    nb1 = find_1stnearest_support(coord,support_df)\n",
    "    x, y, z = nb1\n",
    "    support_df['parsed'] = support_df['points_specified'].apply(parse_tuple)\n",
    "    # Filter for support points on the same y and z (aisle parallel to x)\n",
    "    same_yz = support_df[support_df['parsed'].apply(lambda p: p[1] == y and p[2] == z)]\n",
    "    if len(same_yz) < 2:\n",
    "        raise ValueError(\"Less than two support points found on the aisle parallel to x.\")\n",
    "\n",
    "    # Compute aisle distances (along x only)\n",
    "    aisle_points = []\n",
    "    for _, row in same_yz.iterrows():\n",
    "        sp_x = row['parsed'][0]\n",
    "        aisle_distance = abs(sp_x - coord[0])\n",
    "        aisle_points.append((row['labels'], row['parsed'], aisle_distance))\n",
    "    # Sort by aisle distance from rack\n",
    "    aisle_points.sort(key=lambda tup: tup[2])\n",
    "    return aisle_points # nearest, second_nearest\n",
    "\n",
    "def warehouse_distance_custom(loc1, loc2, storage_df, support_df):\n",
    "    coord1 = get_coords(loc1, storage_df, support_df)\n",
    "    coord2 = get_coords(loc2, storage_df, support_df)\n",
    "    z1, z2 = coord1[2], coord2[2]\n",
    "    x1, y1 = coord1[0], coord1[1]\n",
    "    x2, y2 = coord2[0], coord2[1]\n",
    "\n",
    "    if z1 == z2:\n",
    "        if x1 == x2:\n",
    "            if y1 == y2:\n",
    "                return 0\n",
    "            # Case 1.1: Same x, same z\n",
    "            asile1= find_nearest_support(coord1, support_df)\n",
    "            asile2 = find_nearest_support(coord2, support_df)\n",
    "            # print(asile1)\n",
    "            return abs(y1 - y2) + 2 * abs(asile1[0][2])\n",
    "        elif y1 == y2:\n",
    "            # Case 1.2: Same y, same z\n",
    "            return abs(x1 - x2)\n",
    "        else:\n",
    "            s1 = find_nearest_support(coord1, support_df)\n",
    "            s2 = find_nearest_support(coord2, support_df)\n",
    "            # if (s1[0][0][:2]!='RC') & (s1[1][0][:2]!='RC') & (s2[0][0][:2]!='RC') & (s2[1][0][:2]!='RC'):\n",
    "            support11 = s1[0]\n",
    "            support12 = s1[1]\n",
    "            support21 = s2[0]\n",
    "            support22 = s2[1]\n",
    "            if (support11[1][0]==support21[1][0]):\n",
    "                return support11[2] + support21[2] + abs(support11[1][1]-support21[1][1])\n",
    "            else:\n",
    "                return min(support11[2]+support22[2]+abs(support11[1][1]-support22[1][1]),\n",
    "                support21[2]+support12[2]+abs(support21[1][1]-support12[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72d78ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def parse_tuple(val):\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    return val\n",
    "\n",
    "def get_coords(label, storage_df, support_df):\n",
    "    row = storage_df[storage_df['originalLocation'] == label]\n",
    "    if not row.empty:\n",
    "        return tuple(map(int, row[['x', 'y', 'z']].values[0]))\n",
    "    row = support_df[support_df['labels'] == label]\n",
    "    if not row.empty:\n",
    "        return tuple(map(float, parse_tuple(row['points_specified'].values[0])))\n",
    "    raise ValueError(f\"Label {label} not found.\")\n",
    "\n",
    "def find_1stnearest_support(coord, support_df):\n",
    "    support_points = support_df['points_specified'].apply(parse_tuple)\n",
    "    points = np.array(list(support_points))\n",
    "    dists = np.sum(np.abs(points - np.array(coord)), axis=1)\n",
    "    idx = np.argmin(dists)\n",
    "    return tuple(points[idx])\n",
    "\n",
    "def find_nearest_support(coord, support_df):\n",
    "    \"\"\"\n",
    "    Given a rack coordinate, find both support points on the aisle parallel to x (same y and z).\n",
    "    Returns a list of (label, support_coord, aisle_distance) sorted by aisle_distance from rack.\n",
    "    \"\"\"\n",
    "    nb1 = find_1stnearest_support(coord,support_df)\n",
    "    x, y, z = nb1\n",
    "    support_df['parsed'] = support_df['points_specified'].apply(parse_tuple)\n",
    "    # Filter for support points on the same y and z (aisle parallel to x)\n",
    "    same_yz = support_df[support_df['parsed'].apply(lambda p: p[1] == y and p[2] == z)]\n",
    "    if len(same_yz) < 2:\n",
    "        raise ValueError(\"Less than two support points found on the aisle parallel to x.\")\n",
    "\n",
    "    # Compute aisle distances (along x only)\n",
    "    aisle_points = []\n",
    "    for _, row in same_yz.iterrows():\n",
    "        sp_x = row['parsed'][0]\n",
    "        aisle_distance = abs(sp_x - coord[0])\n",
    "        aisle_points.append((row['labels'], row['parsed'], aisle_distance))\n",
    "    # Sort by aisle distance from rack\n",
    "    aisle_points.sort(key=lambda tup: tup[2])\n",
    "    return aisle_points # nearest, second_nearest nearest tuple (label, parsed_coords(tuple), aisle_distance)\n",
    "\n",
    "def warehouse_distance_custom(loc1, loc2, storage_df, support_df):\n",
    "    coord1 = get_coords(loc1, storage_df, support_df)\n",
    "    coord2 = get_coords(loc2, storage_df, support_df)\n",
    "    z1, z2 = coord1[2], coord2[2]\n",
    "    x1, y1 = coord1[0], coord1[1]\n",
    "    x2, y2 = coord2[0], coord2[1]\n",
    "\n",
    "    if(loc1 == 'CC-08'):\n",
    "        a2 = find_nearest_support(coord2, support_df)\n",
    "        if a2[0][0][:2] == 'CC':\n",
    "            return a2[0][2] + abs(coord1[1] - a2[0][1][1]), [loc1, a2[0][0], loc2]\n",
    "        if a2[1][0][:2] == 'CC':\n",
    "            return a2[1][2] + abs(coord1[1] - a2[1][1][1]), [loc1, a2[1][0], loc2]\n",
    "    if(loc2 == 'CC-08'):\n",
    "        a1 = find_nearest_support(coord1, support_df)\n",
    "        if a1[0][0][:2] == 'CC':\n",
    "            return a1[0][2] + abs(coord2[1] - a1[0][1][1]), [loc1, a1[0][0], loc2]\n",
    "        if a1[1][0][:2] == 'CC':\n",
    "            return a1[1][2] + abs(coord2[1] - a1[1][1][1]), [loc1, a1[1][0], loc2]\n",
    "    # If both locations are not CC-08, proceed with normal distance calculation\n",
    "\n",
    "    if z1 == z2:\n",
    "        if x1 == x2:\n",
    "            if y1 == y2:\n",
    "                return 0, 'NO route'\n",
    "            # Case 1.1: Same x, same z\n",
    "            asile1= find_nearest_support(coord1, support_df)\n",
    "            asile2 = find_nearest_support(coord2, support_df)\n",
    "            # print(asile1)\n",
    "            return abs(asile1[0][1][1] - asile2[0][1][1]) + abs(asile1[0][2]) + abs(asile2[0][2]), [loc1, asile1[0][0], asile2[0][0], loc2]\n",
    "        elif y1 == y2:\n",
    "            # Case 1.2: Same y, same z\n",
    "            return abs(x1 - x2), [loc1, loc2]\n",
    "        else:\n",
    "            s1 = find_nearest_support(coord1, support_df)\n",
    "            s2 = find_nearest_support(coord2, support_df)\n",
    "            # if (s1[0][0][:2]!='RC') & (s1[1][0][:2]!='RC') & (s2[0][0][:2]!='RC') & (s2[1][0][:2]!='RC'):\n",
    "            support11 = s1[0]\n",
    "            support12 = s1[1]\n",
    "            support21 = s2[0]\n",
    "            support22 = s2[1]\n",
    "            if (support11[1][0]==support21[1][0]):\n",
    "                return support11[2] + support21[2] + abs(support11[1][1]-support21[1][1]), [loc1, support11[0], support21[0], loc2]\n",
    "            elif((support11[2]+support22[2]+abs(support11[1][1]-support22[1][1]))<(support21[2]+support12[2]+abs(support21[1][1]-support12[1][1]))):\n",
    "                return support11[2]+support22[2]+abs(support11[1][1]-support22[1][1]), [loc1, support11[0], support22[0], loc2]\n",
    "            else:\n",
    "                return support21[2]+support12[2]+abs(support21[1][1]-support12[1][1]), [loc1, support12[0], support21[0], loc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b4944fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_order_details(waveNumber: int) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Get order details for a specific wave number.\n",
    "    \n",
    "#     Args:\n",
    "#         waveNumber (int): The wave number to filter orders.\n",
    "#         customer_order_df (pd.DataFrame): DataFrame containing customer orders.\n",
    "        \n",
    "#     Returns:\n",
    "#         pd.DataFrame: Filtered DataFrame with orders for the specified wave number.\n",
    "#     \"\"\"\n",
    "#     # waveNumber=33169\n",
    "#     order1 = Customer_Order.loc[Customer_Order[\"waveNumber\"]==waveNumber]\n",
    "#     df_label = pd.DataFrame()\n",
    "#     pro_list = order1[\"Reference\"].unique()\n",
    "#     for i in pro_list:\n",
    "#         for j in range(1,19):\n",
    "#             df_label = pd.concat([random_storage[(random_storage[f'col_{j}_label']== i )],df_label])\n",
    "#     df_label.drop_duplicates(inplace=True)\n",
    "\n",
    "#     locations = df_label['originalLocation'].to_list()\n",
    "#     location_start = 'CC-08'\n",
    "#     # locations.append(location_start)\n",
    "#     products = order1['Reference'].unique()\n",
    "\n",
    "#     random_storage_T = pd.DataFrame(index = order1['Reference'], columns= df_label['originalLocation'])\n",
    "#     random_storage_T.fillna(0.0, inplace=True)\n",
    "#     for idx, row in df_label.iterrows():\n",
    "#         # Access row data, e.g., row['col_1_label'], row['col_1_qty'], etc.\n",
    "#         # print(f\"Row index {idx} data: {row.to_dict()}\")\n",
    "#         dict_ = row.to_dict()\n",
    "#         location = dict_['originalLocation']\n",
    "#         for i in range(1,19):\n",
    "#             ref = f'col_{i}_label'\n",
    "#             quant = f'col_{i}_qty'\n",
    "#             try:\n",
    "#                 random_storage_T.loc[dict_[ref],location]+=dict_[quant]\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "#     q_pi = random_storage_T.copy() #q_pi is the quntity of product p at location i \n",
    "#     q_pi = q_pi.groupby('Reference').sum()\n",
    "#     rp = order1.loc[:,['quantity (units)','Reference']] #quntity of product p required reference as index \n",
    "#     rp = rp.groupby('Reference').sum()\n",
    "#     rp = rp['quantity (units)'].to_dict()\n",
    "\n",
    "#     location_all = locations.copy()\n",
    "#     location_all.append(location_start)\n",
    "#     distance_matrix = pd.DataFrame(index=location_all, columns=location_all)\n",
    "#     for i in location_all:\n",
    "#         for j in location_all:\n",
    "#             distance_matrix.loc[i,j] = warehouse_distance_custom(i,j,storage_location,support_point)[0]\n",
    "\n",
    "#     return q_pi, rp, locations, location_start, products, distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf382e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_details(waveNumber: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get order details for a specific wave number.\n",
    "    \n",
    "    Args:\n",
    "        waveNumber (int): The wave number to filter orders.\n",
    "        customer_order_df (pd.DataFrame): DataFrame containing customer orders.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with orders for the specified wave number.\n",
    "    \"\"\"\n",
    "    # waveNumber=33169\n",
    "    order1 = Customer_Order.loc[Customer_Order[\"waveNumber\"]==waveNumber]\n",
    "    df_label = pd.DataFrame()\n",
    "    pro_list = order1[\"Reference\"].unique()\n",
    "    for i in pro_list:\n",
    "        for j in range(1,19):\n",
    "            df_label = pd.concat([random_storage[(random_storage[f'col_{j}_label']== i )],df_label])\n",
    "    df_label.drop_duplicates(inplace=True)\n",
    "\n",
    "    locations = df_label['originalLocation'].to_list()\n",
    "    location_start = 'CC-08'\n",
    "    # locations.append(location_start)\n",
    "    products = order1['Reference'].unique()\n",
    "    rp = order1.loc[:,['quantity (units)','Reference']] #quntity of product p required reference as index \n",
    "    rp = rp.groupby('Reference').sum()\n",
    "    rp = rp['quantity (units)'].to_dict()\n",
    "\n",
    "    location_all = locations.copy()\n",
    "    location_all.append(location_start)\n",
    "\n",
    "    return rp, locations, location_start, products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb25295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b0ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db2ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "order1 = Customer_Order[Customer_Order['waveNumber']==43175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "794c522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pi1 = q_pi[q_pi.index.isin(order1.Reference.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "649aa881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = q_pi1.loc[:, (q_pi1 != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d85d7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.columns.str.match(r'^[C-D]-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b5c3a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f89237fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pi1 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca16dd0",
   "metadata": {},
   "source": [
    "# Random code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc9cade-6f97-46c0-9342-b57324591957",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_files\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFormOR\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluase_extractor, formulation_objective_constraints,formulation, define_llm\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_files\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSelfReflexOR\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explanation_agent, code_gen_agent,critique_on_problem_dec\n\u001b[1;32m      4\u001b[0m openai \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# problem = \"A company plans to run an advertising campaign across multiple media platforms, such as TV, radio, online, and print. Each platform has a different cost per advertisement and a different expected audience reach. The company has a fixed advertising budget and wants to distribute it across the platforms in the most effective way. The goal is to determine how much money to allocate to each platform in order to maximize total market reach, without exceeding the overall advertising budget. Negative expenditures on any platform are not allowed.\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# problem = \"There has been an oil spill in the ocean and ducks need to be taken to shore to be cleaned either by boat or by canoe. A boat can take 10 ducks per trip while a canoe can take 8 ducks per trip. Since the boats are motor powered, they take 20 minutes per trip while the canoes take 40 minutes per trip. In order to avoid further environmental damage, there can be at most 12 boat trips and at least 60% of the trips should be by canoe. If at least 300 ducks need to be taken to shore, how many of each transportation method should be used to minimize the total amount of time needed to transport the ducks?\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# problem = \"\"\"A manufacturing company needs to plan how to produce a product over a 20-day period. Every time the company starts producing the product, it incurs a fixed setup cost, regardless of how much is produced. Once the machine is set up, the company can produce any quantity of the product.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Demand 50 67 83 40 10 25 78 66 5 20 3 25 90 34 67 76 20 43 15 56\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/iimmu/wareBuddy/utils_files/SelfReflexOR.py:23\u001b[0m\n\u001b[1;32m     18\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#defining llm \u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#llm for formulation\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# llm_formulator = ChatOrlm(model_path = \"./models/ORLM\",max_new_tokens=1000000)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m llm_formulator \u001b[38;5;241m=\u001b[39m ChatOpenAI(model\u001b[38;5;241m=\u001b[39mmodel_name, temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# llm_formulator = ChatGroq(model=model_name, temperature = 0)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_files\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mFormOR\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m define_llm, ExplanationCritiqueOutput, LatexOutputParser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_core/load/serializable.py:130\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:743\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(\n\u001b[1;32m    737\u001b[0m             proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_proxy, verify\u001b[38;5;241m=\u001b[39mglobal_ssl_context\n\u001b[1;32m    738\u001b[0m         )\n\u001b[1;32m    739\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _get_default_httpx_client(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai_api_base, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_timeout)\n\u001b[1;32m    742\u001b[0m     }\n\u001b[0;32m--> 743\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclient_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msync_specific)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/openai/_client.py:130\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    128\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from utils_files.FormOR import cluase_extractor, formulation_objective_constraints,formulation, define_llm\n",
    "from utils_files.SelfReflexOR import explanation_agent, code_gen_agent,critique_on_problem_dec\n",
    "\n",
    "openai = True\n",
    "# problem = \"A company plans to run an advertising campaign across multiple media platforms, such as TV, radio, online, and print. Each platform has a different cost per advertisement and a different expected audience reach. The company has a fixed advertising budget and wants to distribute it across the platforms in the most effective way. The goal is to determine how much money to allocate to each platform in order to maximize total market reach, without exceeding the overall advertising budget. Negative expenditures on any platform are not allowed.\"\n",
    "# problem = \"There has been an oil spill in the ocean and ducks need to be taken to shore to be cleaned either by boat or by canoe. A boat can take 10 ducks per trip while a canoe can take 8 ducks per trip. Since the boats are motor powered, they take 20 minutes per trip while the canoes take 40 minutes per trip. In order to avoid further environmental damage, there can be at most 12 boat trips and at least 60% of the trips should be by canoe. If at least 300 ducks need to be taken to shore, how many of each transportation method should be used to minimize the total amount of time needed to transport the ducks?\"\n",
    "# problem = \"\"\"A manufacturing company needs to plan how to produce a product over a 20-day period. Every time the company starts producing the product, it incurs a fixed setup cost, regardless of how much is produced. Once the machine is set up, the company can produce any quantity of the product.\n",
    "\n",
    "# If the product is not used immediately after production, it is stored in a warehouse, which incurs a holding cost per unit per day. There is no upper limit on how much the company can produce in a day or how much can be stored in inventory.\n",
    "\n",
    "# The company must meet a known daily demand for the product over the 20 days. It starts with some initial inventory available on the first day. The main trade-off the company faces is:\n",
    "\n",
    "# There should be no inventory left over at the last day of planning horizon\n",
    "\n",
    "# Producing in large batches reduces setup costs because production is done less frequently, but leads to higher inventory and storage costs.\n",
    "\n",
    "# Producing in smaller batches increases setup costs due to more frequent production runs, but reduces inventory holding costs.\n",
    "\n",
    "# The objective is to decide when to produce and how much to produce on each day in order to meet all the demand while minimizing the total cost, which includes both setup and holding costs.\n",
    "\n",
    "# The specific values are as follows:\n",
    "\n",
    "# Planning horizon: 20 days\n",
    "\n",
    "# Known demand for each day\n",
    "\n",
    "# Setup cost per production run: ₹300\n",
    "\n",
    "# Holding cost per unit per day: ₹2\n",
    "\n",
    "# Initial inventory at the start of Day 1: 20 units\n",
    "\n",
    "# The goal is to create a cost-efficient production schedule that ensures all customer demand is satisfied on time with minimum total cost.\n",
    "# Day 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n",
    "# Demand 50 67 83 40 10 25 78 66 5 20 3 25 90 34 67 76 20 43 15 56\n",
    "# \"\"\"\n",
    "\n",
    "problem = \"\"\"\n",
    "A warehouse needs to fulfill customer orders for a variety of products over a set period. Each day, there is a specific list of products and quantities that must be picked and shipped to customers. The warehouse is organized into aisles and shelves, and each product can be found in one or more locations within the warehouse.\n",
    "\n",
    "To collect the products, a worker (called a \"picker\") must travel through the warehouse, moving from one shelf to another to gather the required items. The main challenge is to plan the picker’s route so that all products are collected efficiently, with the least amount of walking or travel distance.\n",
    "\n",
    "There are a few important considerations:\n",
    "\n",
    "Each product on the order list may be available in multiple locations, but the picker only needs to collect enough to meet the required quantity for that day.\n",
    "\n",
    "The picker can choose which locations to visit, as long as the total picked meets the demand for each product.\n",
    "\n",
    "For each move between two locations in the warehouse, there is a known distance or travel cost.\n",
    "\n",
    "The picker starts and ends at a designated point (such as the warehouse entrance or packing area).\n",
    "\n",
    "The goal is to create a picking route that visits all the necessary locations, collects all the required products in the right quantities, and returns to the starting point, all while minimizing the total distance traveled.\n",
    "\n",
    "The main trade-off is between picking from fewer locations (which might mean more walking but fewer stops) versus picking from more locations (which might reduce walking but increase the number of stops and complexity).\n",
    "\n",
    "The warehouse manager needs to decide:\n",
    "\n",
    "Which locations the picker should visit to collect the needed quantities of each product.\n",
    "\n",
    "The order in which the picker should visit these locations, to ensure the shortest possible route.\n",
    "\n",
    "The solution should ensure that:\n",
    "\n",
    "All customer orders are fulfilled in full and on time.\n",
    "\n",
    "The picker’s total travel distance is as short as possible, to save time and reduce operational costs.\n",
    "\n",
    "The route is continuous, with no unnecessary backtracking or disconnected loops.\n",
    "\n",
    "This problem is especially challenging as the number of products and possible picking locations increases, making it difficult to find the absolute best route quickly. Therefore, efficient planning and smart algorithms are needed to optimize the picking process and keep costs low.\n",
    "\"\"\"\n",
    "cluase = cluase_extractor(problem, True)\n",
    "final = cluase.run()\n",
    "\n",
    "formulation_obj_con = formulation_objective_constraints(problem, final, openai=openai)\n",
    "constraint, objective = formulation_obj_con.run()\n",
    "\n",
    "form = formulation(final,constraint, objective, openai=openai)\n",
    "final_formulation = form.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e94d1-91f1-4a5a-a469-c6d7f1f8b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "gurobi_prompt = PromptTemplate(\n",
    "    input_variables=[\"formulation\"],\n",
    "    template=\"\"\"\n",
    "ROLE: You are a MASTER IN GUROBI PY CODING AND GIVEN THE FORMULATION YOU ARE TASKED TO CODE THE FORMULATION GIVEN TO YOU .\n",
    "    if data is given to you then take that data \n",
    "    if data is not given to you then create data on your own which should be less and solvable by solver\n",
    "    FORMULATION:\n",
    "    {formulation}\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    1. Always define T from 0\n",
    "    2. Print Decision varibles \n",
    "        if binary then only those with 1 \n",
    "        \n",
    "\n",
    "    FORMAT REQUIREMENTS:\n",
    "    - Keep core model formulation intact\n",
    "    - Use Python f-strings for dynamic parameter injection\n",
    "    - Import correct libraries and modules \n",
    "\n",
    "    \n",
    "    RETURN FULL PYTHON CODE IN ```..``` so that it will be easy to extract afterward.\n",
    "    \"\"\"\n",
    "\n",
    ")\n",
    "\n",
    "gurobi_chain = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    prompt=gurobi_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "code = gurobi_chain.run({\n",
    "    \"formulation\":final_formulation\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e284fac-8fb2-4291-84fd-b32741741cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc447d-64c6-4bda-b385-717d1f69a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'python\\nfrom gurobipy import *\\n\\n# Sets and Indices\\nproducts = [\\'p1\\', \\'p2\\', \\'p3\\']\\nlocations = [\\'l1\\', \\'l2\\', \\'l3\\', \\'l4\\']\\npairs = [(i,j) for i in locations for j in locations]\\n\\n# Parameters\\na = {(\\'p1\\',\\'l1\\'): 10, (\\'p1\\',\\'l2\\'): 5, (\\'p1\\',\\'l3\\'): 7, (\\'p1\\',\\'l4\\'): 8,\\n     (\\'p2\\',\\'l1\\'): 6, (\\'p2\\',\\'l2\\'): 8, (\\'p2\\',\\'l3\\'): 9, (\\'p2\\',\\'l4\\'): 7,\\n     (\\'p3\\',\\'l1\\'): 8, (\\'p3\\',\\'l2\\'): 9, (\\'p3\\',\\'l3\\'): 6, (\\'p3\\',\\'l4\\'): 10}\\n\\nd = {\\'p1\\': 15, \\'p2\\': 20, \\'p3\\': 18}\\n\\nc = {(i,j): 10 for i,j in pairs}\\n\\ns = \\'l1\\'\\nM = 1000\\n\\n# Model\\nm = Model(\"warehouse\")\\n\\n# Decision Variables\\nx = m.addVars(products, locations, vtype=GRB.INTEGER, name=\"x\")\\ny = m.addVars(pairs, vtype=GRB.BINARY, name=\"y\")\\nz = m.addVars(locations, vtype=GRB.BINARY, name=\"z\")\\nu = m.addVars(locations, vtype=GRB.CONTINUOUS, name=\"u\")\\n\\n# Objective Function\\nm.setObjective(quicksum(c[i,j]*y[i,j] for i,j in pairs), GRB.MINIMIZE)\\n\\n# Constraints\\nm.addConstrs((quicksum(x[p,l] for l in locations) == d[p] for p in products), \"product\")\\nm.addConstrs((x[p,l] <= a[p,l] for p in products for l in locations), \"availability\")\\nm.addConstrs((quicksum(x[p,l] for p in products) <= M*z[l] for l in locations), \"visit\")\\nm.addConstr(quicksum(y[s,j] for j in locations if j != s) == 1, \"start\")\\nm.addConstrs((quicksum(y[i,l] for i in locations) == quicksum(y[l,j] for j in locations) for l in locations), \"flow\")\\nm.addConstrs((u[i] - u[j] + len(locations)*y[i,j] <= len(locations) - 1 for i in locations for j in locations if i != j and i != s and j != s), \"subtour\")\\n\\n# Solve\\nm.optimize()\\n\\n# Print solution\\nfor v in m.getVars():\\n    if v.x > 0:\\n        print(f\\'{v.varName} = {v.x}\\')\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532b50f-af04-4589-bf0e-64294099d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "ip = get_ipython()\n",
    "ip.set_next_input(code, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa02a6-c4ae-428a-958d-9c488ddf8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "\n",
    "# Sets and Indices\n",
    "products = ['p1', 'p2', 'p3']\n",
    "locations = ['l1', 'l2', 'l3', 'l4']\n",
    "pairs = [(i,j) for i in locations for j in locations]\n",
    "\n",
    "# Parameters\n",
    "a = {('p1','l1'): 10, ('p1','l2'): 5, ('p1','l3'): 7, ('p1','l4'): 8,\n",
    "     ('p2','l1'): 6, ('p2','l2'): 8, ('p2','l3'): 9, ('p2','l4'): 7,\n",
    "     ('p3','l1'): 8, ('p3','l2'): 9, ('p3','l3'): 6, ('p3','l4'): 10}\n",
    "\n",
    "d = {'p1': 15, 'p2': 20, 'p3': 18}\n",
    "\n",
    "c = {(i,j): 10 for i,j in pairs}\n",
    "\n",
    "s = 'l1'\n",
    "M = 1000\n",
    "\n",
    "# Model\n",
    "m = Model(\"warehouse\")\n",
    "\n",
    "# Decision Variables\n",
    "x = m.addVars(products, locations, vtype=GRB.INTEGER, name=\"x\")\n",
    "y = m.addVars(pairs, vtype=GRB.BINARY, name=\"y\")\n",
    "z = m.addVars(locations, vtype=GRB.BINARY, name=\"z\")\n",
    "u = m.addVars(locations, vtype=GRB.CONTINUOUS, name=\"u\")\n",
    "\n",
    "# Objective Function\n",
    "m.setObjective(quicksum(c[i,j]*y[i,j] for i,j in pairs), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "m.addConstrs((quicksum(x[p,l] for l in locations) == d[p] for p in products), \"product\")\n",
    "m.addConstrs((x[p,l] <= a[p,l] for p in products for l in locations), \"availability\")\n",
    "m.addConstrs((quicksum(x[p,l] for p in products) <= M*z[l] for l in locations), \"visit\")\n",
    "m.addConstr(quicksum(y[s,j] for j in locations if j != s) == 1, \"start\")\n",
    "m.addConstrs((quicksum(y[i,l] for i in locations) == quicksum(y[l,j] for j in locations) for l in locations), \"flow\")\n",
    "m.addConstrs((u[i] - u[j] + len(locations)*y[i,j] <= len(locations) - 1 for i in locations for j in locations if i != j and i != s and j != s), \"subtour\")\n",
    "\n",
    "# Solve\n",
    "m.optimize()\n",
    "\n",
    "# Print solution\n",
    "for v in m.getVars():\n",
    "    if v.x > 0:\n",
    "        print(f'{v.varName} = {v.x}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e41e0-1ded-4d01-93bc-c75b7dd0f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Define data structure\n",
    "data = {\n",
    "    'Period': [1, 2, 3, 4],                  # Time periods\n",
    "    'Demand': [100, 150, 120, 130],          # Units required in each period\n",
    "    'Ordering_Cost_per_Unit': [2, 2, 2, 2],  # Ordering cost per unit (could vary)\n",
    "    'Holding_Cost_per_Unit': [1, 1, 1, 1],   # Holding cost per unit carried over\n",
    "    'Order_Capacity': [200, 200, 200, 200],  # Max units that can be ordered in the period\n",
    "    'Order_Quantity': [0, 0, 0, 0],          # Decision variable (to be filled by optimization)\n",
    "    'Inventory': [0, 0, 0, 0],               # Ending inventory after demand is met\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# df.set_index('Period', inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "data_agent = create_pandas_dataframe_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    df,\n",
    "    verbose=False,\n",
    "    allow_dangerous_code=True\n",
    ")\n",
    "\n",
    "\n",
    "# # from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "# # from langchain.chat_models import ChatOpenAI\n",
    "# # import pandas as pd\n",
    "\n",
    "# # STEP 1: Create your DataFrames\n",
    "\n",
    "\n",
    "# # STEP 2: Build the agent with a list of DataFrames\n",
    "# data_agent = create_pandas_dataframe_agent(\n",
    "#     ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "#     [ra, df2, df3], \n",
    "#     verbose=True,\n",
    "#     allow_dangerous_code=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee603c28-a228-46d8-97fc-7e170e62352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "request_prompt = PromptTemplate(\n",
    "    input_variables=[\"formulation\"],\n",
    "    template=\"\"\"\n",
    "You are an OR data assistant.\n",
    "\n",
    "Given this optimization formulation:\n",
    "{formulation}\n",
    "\n",
    "List the *exact* data needed from a pandas DataFrame as Python queries.\n",
    "For example: \"Give me the demand for each item as a list\", \"Get the holding costs by location as a dictionary\", etc.\n",
    "\n",
    "Output one or more clear data requests.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "request_chain = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    prompt=request_prompt,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de344d5-abca-43f7-b0ff-0636194edff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: User provides formulation\n",
    "formulation_text = \"\"\"\n",
    "Minimize total cost = ∑(ordering cost × order quantity + holding cost × inventory)\n",
    "\n",
    "Subject to:\n",
    "- Demand must be met for each period\n",
    "- Inventory balance across periods\n",
    "- Order quantity ≤ capacity\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Agent C generates data requests\n",
    "data_query = request_chain.run(formulation=formulation_text)\n",
    "print(\"Data request from Agent C:\", data_query)\n",
    "\n",
    "# Step 3: Agent A extracts data\n",
    "extracted_data = data_agent.run(data_query)\n",
    "print(\"Extracted data:\", extracted_data)\n",
    "\n",
    "# Step 4: Send it to Agent B (Gurobi executor agent)\n",
    "gurobi_prompt = f\"\"\"\n",
    "Use this data:\n",
    "{extracted_data}\n",
    "\n",
    "Formulation:\n",
    "{formulation_text}\n",
    "\n",
    "Use gurobipy to build and solve the model. Print the final objective value and variable values.\n",
    "\"\"\"\n",
    "\n",
    "result = gurobi_executor_agent.run(gurobi_prompt)\n",
    "print(\"Gurobi solution:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db3c3c-b838-4149-bc51-f80f81a3f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "\n",
    "# Step 1: LLM setup\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "\n",
    "# Step 2: Tool to execute code\n",
    "python_tool = PythonREPLTool()\n",
    "\n",
    "# Step 3: Combine tool and LLM into an agent\n",
    "gurobi_executor_agent = initialize_agent(\n",
    "    tools=[python_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7841386-a82f-47b8-8fe2-56cc4ad2f37b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 4: Send it to Agent B (Gurobi executor agent)\n",
    "gurobi_prompt = f\"\"\"\n",
    "Use this data:\n",
    "{extracted_data}\n",
    "\n",
    "Formulation:\n",
    "{formulation_text}\n",
    "\n",
    "Use gurobipy to build and solve the model. Print the final objective value and variable values.\n",
    "\"\"\"\n",
    "\n",
    "result = gurobi_executor_agent.run(gurobi_prompt)\n",
    "print(\"Gurobi solution:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e455f5-467c-49ae-b809-ea9f573a13fe",
   "metadata": {},
   "source": [
    "# experiment 1\n",
    "\n",
    "## agents \n",
    "1. formulation agent\n",
    "2. data extraction request agent \n",
    "3. data extraction agent \n",
    "4. if no of locations are <50 gurobi solver agent else \n",
    "5. strategy agent (finding best huristic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc5dd1-bc4e-4e69-b59e-b283f23afe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "\n",
    "#formulation agent\n",
    "from utils_files.FormOR import cluase_extractor, formulation_objective_constraints,formulation, define_llm\n",
    "from utils_files.SelfReflexOR import explanation_agent, code_gen_agent,critique_on_problem_dec\n",
    "\n",
    "openai = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f07f94-4204-4d43-8c06-2ca2a7195849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# problem = \"A company plans to run an advertising campaign across multiple media platforms, such as TV, radio, online, and print. Each platform has a different cost per advertisement and a different expected audience reach. The company has a fixed advertising budget and wants to distribute it across the platforms in the most effective way. The goal is to determine how much money to allocate to each platform in order to maximize total market reach, without exceeding the overall advertising budget. Negative expenditures on any platform are not allowed.\"\n",
    "# problem = \"There has been an oil spill in the ocean and ducks need to be taken to shore to be cleaned either by boat or by canoe. A boat can take 10 ducks per trip while a canoe can take 8 ducks per trip. Since the boats are motor powered, they take 20 minutes per trip while the canoes take 40 minutes per trip. In order to avoid further environmental damage, there can be at most 12 boat trips and at least 60% of the trips should be by canoe. If at least 300 ducks need to be taken to shore, how many of each transportation method should be used to minimize the total amount of time needed to transport the ducks?\"\n",
    "# problem = \"\"\"A manufacturing company needs to plan how to produce a product over a 20-day period. Every time the company starts producing the product, it incurs a fixed setup cost, regardless of how much is produced. Once the machine is set up, the company can produce any quantity of the product.\n",
    "\n",
    "# If the product is not used immediately after production, it is stored in a warehouse, which incurs a holding cost per unit per day. There is no upper limit on how much the company can produce in a day or how much can be stored in inventory.\n",
    "\n",
    "# The company must meet a known daily demand for the product over the 20 days. It starts with some initial inventory available on the first day. The main trade-off the company faces is:\n",
    "\n",
    "# There should be no inventory left over at the last day of planning horizon\n",
    "\n",
    "# Producing in large batches reduces setup costs because production is done less frequently, but leads to higher inventory and storage costs.\n",
    "\n",
    "# Producing in smaller batches increases setup costs due to more frequent production runs, but reduces inventory holding costs.\n",
    "\n",
    "# The objective is to decide when to produce and how much to produce on each day in order to meet all the demand while minimizing the total cost, which includes both setup and holding costs.\n",
    "\n",
    "# The specific values are as follows:\n",
    "\n",
    "# Planning horizon: 20 days\n",
    "\n",
    "# Known demand for each day\n",
    "\n",
    "# Setup cost per production run: ₹300\n",
    "\n",
    "# Holding cost per unit per day: ₹2\n",
    "\n",
    "# Initial inventory at the start of Day 1: 20 units\n",
    "\n",
    "# The goal is to create a cost-efficient production schedule that ensures all customer demand is satisfied on time with minimum total cost.\n",
    "# Day 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n",
    "# Demand 50 67 83 40 10 25 78 66 5 20 3 25 90 34 67 76 20 43 15 56\n",
    "# \"\"\"\n",
    "\n",
    "problem = \"\"\"\n",
    "A shoe ware warehouse needs to fulfill customer orders for a variety of products. there is a specific list of products and quantities that must be picked and shipped to customers. The warehouse is organized into aisles and shelves, and each product can be found in one or more locations within the warehouse.\n",
    "\n",
    "To collect the products, a worker (called a \"picker\") must travel through the warehouse, moving from one shelf to another to gather the required items. The main challenge is to plan the picker’s route so that all products are collected efficiently, with the least amount of walking or travel distance.\n",
    "\n",
    "There are a few important considerations:\n",
    "\n",
    "Each product on the order list may be available in multiple locations, but the picker only needs to collect one product from only one location.\n",
    "for example:    \n",
    "p1, p2, p3 are products, l1,l2,l3,l4,l5,l6,l7 are the locations  \n",
    "Available_df = p1:[2,0,0,2,0,0,0]\n",
    "               p2:[0,0,2,0,4,0,0]\n",
    "               p3:[0,0,0,0,1,0,3]\n",
    "demand = {{'p1':1, 'p2':2, 'p3': 1}}\n",
    "p1: l1, l4 (for p1 picker should visit l1 or l4)\n",
    "p2: l3, l5 (for p2 picker should visit l3 or l5)s\n",
    "p3: l5, l7 (for p3 picker should visit l5 or l7)\n",
    "so one route can be s->l1->l3->l5->s, here no need to visit all the locations l1, l2, l3 etc. just l1 l3 l5 is sufficient\n",
    "\n",
    "The picker can choose which locations to visit, as long as the total picked meets the demand for each product. No need to visit all the location but we have to visit at least one location for each product\n",
    "\n",
    "For each move between two locations in the warehouse, there is a known distance or travel cost.\n",
    "\n",
    "The picker starts and ends at a designated point (such as the warehouse entrance or packing area).\n",
    "\n",
    "The goal is to create a picking route that can fullfill the required amount of product in that pick list , and returns to the starting point, all while minimizing the total distance traveled.\n",
    "\n",
    "The main trade-off is between picking from fewer locations (which might mean more walking but fewer stops) versus picking from more locations (which might reduce walking but increase the number of stops and complexity).\n",
    "\n",
    "The warehouse manager needs to decide:\n",
    "\n",
    "Which locations the picker should visit.\n",
    "\n",
    "The order in which the picker should visit these locations, to ensure the shortest possible route.\n",
    "\n",
    "The solution should ensure that:\n",
    "\n",
    "All customer orders are fulfilled in full.\n",
    "\n",
    "The picker’s total travel distance is as short as possible, to save time and reduce operational costs.\n",
    "\n",
    "picker should start from start point and after the picking it should end at the start point only\n",
    "\n",
    "The route is continuous, with no unnecessary backtracking or disconnected loops.\n",
    "\"\"\"\n",
    "\n",
    "problem = \"\"\"\n",
    "**Warehouse Order Picking Problem**\n",
    "\n",
    "You are given a warehouse layout where a worker (called a \"picker\") must collect and fulfill customer product orders. The goal is to plan the picker's route through the warehouse so that:\n",
    "\n",
    "- All products in the order are picked.\n",
    "- The total travel distance is minimized.\n",
    "- The picker starts and ends at a designated starting point (e.g., the warehouse entrance).\n",
    "\n",
    "**Problem Description**\n",
    "\n",
    "- There is a list of products, each with a specific demand quantity.\n",
    "- Each product may be stored in multiple warehouse locations (aisles/shelves).\n",
    "- A product can be picked from any one of its available locations, as long as the available quantity at that location is enough to meet the demand.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Products:\n",
    "- p1, p2, p3\n",
    "\n",
    "Locations:\n",
    "- l1, l2, l3, l4, l5, l6, l7\n",
    "\n",
    "Availability:\n",
    "Available_df = {\n",
    "    'p1': [2, 0, 0, 2, 0, 0, 0],  # Available at l1 and l4\n",
    "    'p2': [0, 0, 2, 0, 4, 0, 0],  # Available at l3 and l5\n",
    "    'p3': [0, 0, 0, 0, 1, 0, 3]   # Available at l5 and l7\n",
    "}\n",
    "\n",
    "Demand:\n",
    "demand = {'p1': 1, 'p2': 2, 'p3': 1}\n",
    "\n",
    "Example Selection:\n",
    "- Pick p1 from l1\n",
    "- Pick p2 from l5\n",
    "- Pick p3 from l7\n",
    "\n",
    "Resulting Route:\n",
    "start → l1 → l5 → l7 → start\n",
    "\n",
    "This route satisfies:\n",
    "- All demands are met from a valid location with sufficient stock.\n",
    "- Shortest possible travel path is attempted (based on cost/distance matrix).\n",
    "\n",
    "**Constraints**\n",
    "\n",
    "1. Each product must be picked in full from one valid location (with enough available stock).\n",
    "2. Only one location per product is selected.\n",
    "3. Only necessary locations (those selected for picking) should be visited.\n",
    "4. The picker must start and end at the same start point.\n",
    "5. The travel route must be continuous (no disconnected paths or loops).\n",
    "6. The total distance traveled should be minimized.\n",
    "\n",
    "**Optimization Objective**\n",
    "\n",
    "Determine:\n",
    "1. Which location to pick each product from (ensuring feasibility).\n",
    "2. The sequence in which to visit those locations.\n",
    "3. A complete route that starts and ends at the depot and minimizes total travel distance.\n",
    "\"\"\"\n",
    "\n",
    "# cluase = cluase_extractor(problem, True)\n",
    "# final = cluase.run()\n",
    "\n",
    "# formulation_obj_con = formulation_objective_constraints(problem, final, openai=openai)\n",
    "# constraint, objective = formulation_obj_con.run()\n",
    "\n",
    "# form = formulation(final,constraint, objective, openai=openai)\n",
    "# final_formulation = form.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cbd5b-032f-4ccf-9944-412ac2215c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: User provides formulation\n",
    "formulation_text = \"\"\"\\textbf{{Sets and Parameters:}}\n",
    "\n",
    "\\begin{{itemize}}\n",
    "    \\item $P$: set of products to be picked (picking list)\n",
    "    \\item $V$: set of vertices (positions in front of warehouse shelves)\n",
    "    \\item $E$: set of edges (aisles or cross-aisles in the warehouse)\n",
    "    \\item $S_p$: set of positions where product $p$ can be found, $\\forall p \\in P$\n",
    "    \\item $d_{i,j}$: distance between positions $i$ and $j$ in the warehouse\n",
    "    \\item $q_{p,i}$: quantity of product $p$ available at position $i$\n",
    "    \\item $r_p$: required quantity of product $p$\n",
    "    \\item $G(V, E)$: warehouse graph\n",
    "    \\item $D = [d_{i,j}]$: adjacency matrix of $G(V, E)$\n",
    "    \\item $C^t$: set of all possible subtours\n",
    "\\end{{itemize}}\n",
    "\n",
    "\\textbf{{Decision Variables:}}\n",
    "\\begin{{itemize}}\n",
    "    \\item $z_{{i,j}} \\in \\{0, 1\\}$: 1 if edge $(i, j)$ is traversed, 0 otherwise\n",
    "    \\item $y_i \\in \\{0, 1\\}$: 1 if position $i$ is visited, 0 otherwise\n",
    "\\end{{itemize}}\n",
    "\n",
    "\\textbf{Objective:}\n",
    "\\begin{equation}\n",
    "    \\min \\sum_{{(i,j) \\in E} d_{i,j} z_{i,j}}\n",
    "\\end{equation}\n",
    "\n",
    "\\textbf{Subject to:}\n",
    "\\begin{align}\n",
    "    &\\sum_{i \\in S_p} q_{p,i} y_i \\geq r_p, \\quad \\forall p \\in P \\tag{2} \\\\\n",
    "    &\\sum_{i \\in V \\setminus \\{j\\}} z_{i,j} = y_j, \\quad \\forall j \\in V \\tag{3} \\\\\n",
    "    &\\sum_{j \\in V \\setminus \\{i\\}} z_{i,j} = y_i, \\quad \\forall i \\in V \\tag{4} \\\\\n",
    "    &\\sum_{i \\in V(C)} \\sum_{j \\in V(C)} z_{i,j} \\leq |C| - 1, \\quad \\forall C \\in C^t \\tag{5} \\\\\n",
    "    &z_{i,j} \\in \\{0, 1\\}, \\quad \\forall (i, j) \\in E \\tag{6} \\\\\n",
    "    &y_i \\in \\{0, 1\\}, \\quad \\forall i \\in V \\tag{7}\n",
    "\\end{align}\n",
    "\"\"\"\n",
    "formulation_text = '\\\\textbf{Sets:} \\\\\\\\\\n\\\\begin{aligned}\\n& P: \\\\text{ set of products} \\\\quad (p \\\\in P) \\\\\\\\\\n& L: \\\\text{ set of warehouse locations} \\\\quad (l \\\\in L) \\\\\\\\\\n& S: \\\\text{ starting/ending location} \\\\quad (s \\\\in L) \\\\\\\\\\n\\\\end{aligned}\\n\\n\\\\\\\\[2ex]\\n\\n\\\\textbf{Parameters:} \\\\\\\\\\n\\\\begin{aligned}\\n& d_p: \\\\text{ required quantity of product } p \\\\text{ to be picked} \\\\quad (\\\\forall\\\\, p \\\\in P) \\\\\\\\\\n& a_{l,p}: \\\\text{ available quantity of product } p \\\\text{ at location } l \\\\quad (\\\\forall\\\\, l \\\\in L,\\\\, p \\\\in P) \\\\\\\\\\n& c_{l_1, l_2}: \\\\text{ travel distance or cost from location } l_1 \\\\text{ to } l_2 \\\\quad (\\\\forall\\\\, l_1, l_2 \\\\in L,\\\\, l_1 \\\\neq l_2) \\\\\\\\\\n& s: \\\\text{ designated starting/ending location} \\\\quad (s \\\\in L) \\\\\\\\\\n& M: \\\\text{ sufficiently large constant (for linking constraints)} \\\\\\\\\\n\\\\end{aligned}\\n\\n\\\\\\\\[2ex]\\n\\n\\\\textbf{Decision Variables:} \\\\\\\\\\n\\\\begin{aligned}\\n& x_{l,p}: \\\\text{ number of units of product } p \\\\text{ picked from location } l \\\\quad (\\\\forall\\\\, l \\\\in L,\\\\, p \\\\in P) \\\\\\\\\\n& y_{l_1, l_2}: \\n\\\\begin{cases}\\n1, & \\\\text{if picker travels directly from } l_1 \\\\text{ to } l_2 \\\\\\\\\\n0, & \\\\text{otherwise}\\n\\\\end{cases}\\n\\\\quad (\\\\forall\\\\, l_1, l_2 \\\\in L,\\\\, l_1 \\\\neq l_2) \\\\\\\\\\n& z_l: \\n\\\\begin{cases}\\n1, & \\\\text{if location } l \\\\text{ is visited} \\\\\\\\\\n0, & \\\\text{otherwise}\\n\\\\end{cases}\\n\\\\quad (\\\\forall\\\\, l \\\\in L) \\\\\\\\\\n& u_l: \\\\text{ auxiliary variable for subtour elimination} \\\\quad (\\\\forall\\\\, l \\\\in L) \\\\\\\\\\n\\\\end{aligned}\\n\\n\\\\\\\\[2ex]\\n\\n\\\\textbf{Objective Function:} \\\\\\\\\\n\\\\begin{aligned}\\n\\\\text{Minimize} \\\\quad & \\\\sum_{l_1 \\\\in L} \\\\sum_{\\\\substack{l_2 \\\\in L \\\\\\\\ l_2 \\\\neq l_1}} c_{l_1, l_2} \\\\cdot y_{l_1, l_2}\\n\\\\end{aligned}\\n\\n\\\\\\\\[2ex]\\n\\n\\\\textbf{Constraints:} \\\\\\\\\\n\\\\begin{aligned}\\n& \\\\sum_{l \\\\in L} x_{l,p} = d_p \\\\qquad && \\\\forall\\\\, p \\\\in P \\\\\\\\\\n& x_{l,p} \\\\leq a_{l,p} \\\\qquad && \\\\forall\\\\, l \\\\in L,\\\\, p \\\\in P \\\\\\\\\\n& \\\\sum_{p \\\\in P} x_{l,p} \\\\leq M \\\\cdot z_l \\\\qquad && \\\\forall\\\\, l \\\\in L \\\\\\\\\\n& \\\\sum_{\\\\substack{l \\\\in L \\\\\\\\ l \\\\neq s}} y_{s, l} = 1 \\\\\\\\\\n& \\\\sum_{\\\\substack{l \\\\in L \\\\\\\\ l \\\\neq s}} y_{l, s} = 1 \\\\\\\\\\n& \\\\sum_{\\\\substack{l_1 \\\\in L \\\\\\\\ l_1 \\\\neq l}} y_{l_1, l} - \\\\sum_{\\\\substack{l_2 \\\\in L \\\\\\\\ l_2 \\\\neq l}} y_{l, l_2} = 0 \\\\qquad && \\\\forall\\\\, l \\\\in L,\\\\, l \\\\neq s \\\\\\\\\\n& u_{l_1} - u_{l_2} + |L| \\\\cdot y_{l_1, l_2} \\\\leq |L| - 1 \\\\qquad && \\\\forall\\\\, l_1, l_2 \\\\in L \\\\setminus \\\\{s\\\\},\\\\, l_1 \\\\neq l_2 \\\\\\\\\\n& x_{l,p} \\\\geq 0 \\\\qquad && \\\\forall\\\\, l \\\\in L,\\\\, p \\\\in P \\\\\\\\\\n& y_{l_1, l_2} \\\\in \\\\{0,1\\\\} \\\\qquad && \\\\forall\\\\, l_1, l_2 \\\\in L,\\\\, l_1 \\\\neq l_2 \\\\\\\\\\n& z_l \\\\in \\\\{0,1\\\\} \\\\qquad && \\\\forall\\\\, l \\\\in L \\\\\\\\\\n\\\\end{aligned}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b752d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Latex\n",
    "display(Latex(final_formulation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a18271",
   "metadata": {},
   "outputs": [],
   "source": [
    "given_data_set_description = \"\"\"\n",
    "\n",
    "- `q_pi`: A pandas DataFrame with product IDs as rows and location IDs as columns. `q_pi.loc[p][l]` gives the quantity of product `p` available at location `l`.\n",
    "- `rp`: dict with product IDs as keys and required quantities as values. `rp[p]` gives the total quantity required for product `p`.\n",
    "- `distance_matrix`: A square DataFrame with location IDs as both rows and columns, representing the distance between locations.\n",
    "- `products`: A list of product IDs that need to be picked.\n",
    "-`locations`: A list of location IDs where products can be picked.\n",
    "-`location_start`: str The starting location for the picking route. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "initial_pop_description = \"\"\"\n",
    "location is available for product p1 if l1 containts greater then or equal to the unit reuired that is rp[p1]\n",
    " family p1 represents the all the locations where product p1 is available let assume (l1, l2, l3)\n",
    "    family p2 represents the all the locations where product p2 is available lets assume (l4, l5, l6)\n",
    "    family p3 represents the all the locations where product p3 is available lets assume (l7, l8, l9)\n",
    "    etc. \n",
    "    now from this individual solution can represented as in initial population are \n",
    "    1. p1: l1 p2: l4 p3: l7 and so on \n",
    "    2. p2: l5 p1: l2 p3: l8 and so on\n",
    "    3. p1: l3 p2: l6 p3 :l9 and so on\n",
    "    4.p3: l8 p2: l4 p1: l1 and so on\n",
    "    etc.\n",
    "    generate a population of picking route individuals by randomly assigning storage locations for each product based on availability across all storage points. It ensures diversity by permuting the product order and sampling valid locations to form each individual solution.\n",
    "\"\"\"\n",
    "\n",
    "cross_over_description = \"\"\"\n",
    "select two parents randomly from the population and perform crossover with some probability(crossover_rate)\n",
    "and store the new offspring in the new population.\n",
    "\"\"\"\n",
    "\n",
    "mutation_description = \"\"\"\n",
    "randomly select an individual from the population and select two pairs of location from the second half of the individual and swap them \n",
    "\"\"\"\n",
    "\n",
    "fitness_description = \"\"\"\n",
    "calculate the total distance of the picking route by summing the distances between consecutive locations in the picking route, including the return to the starting location.\n",
    "starting location is 'CC-08' distance_matrix is already defined in memory with index and columns as locations\n",
    "\"\"\"\n",
    "\n",
    "selection_description = \"\"\"\n",
    "randomly sample individuls (turnament size) from the population and select the best individual based on fitness function till the population size is reached.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa1f447-18a7-4753-bdeb-b74a9a353500",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from utils_files.code_corrector import CodeCorrector\n",
    "from utils_files.utils import extract_python_code\n",
    "# Template: Metaheuristic code generator\n",
    "code_gen_prompt = PromptTemplate(\n",
    "    input_variables=[\"formulation\"],\n",
    "    template=\"\"\"\n",
    "You are an expert in Python and metaheuristic optimization i.e. Genetic Algorithm\n",
    "\n",
    "You are given an problem description and a mathematical formulation of the problem.\n",
    "\n",
    "here is the problem description:\n",
    "{problem_description}\n",
    "\n",
    "Here is the problem formulation:\n",
    "FORMULATION:\n",
    "{formulation}\n",
    "You are provided the following data objects already defined in memory:\n",
    "{given_data_set_description}\n",
    "\n",
    "Your task:\n",
    "1. representation of initial population \n",
    "   {initial_pop_description}\n",
    "2. Cross over \n",
    "   {cross_over_description}\n",
    "3. Mutation\n",
    "   {mutation_description}\n",
    "4. fitness function\n",
    "   {fitness_description}\n",
    "5. Selection\n",
    "   {selection_description}\n",
    "6. look for edge cases in every block of code and add it in \n",
    "4. Implement the Genetic algorithm using **only** built-in Python modules, **NumPy**, and **Matplotlib**.\n",
    "5. Include **automatic hyperparameter tuning** within the code. Loop over options like population sizes, mutation/cooling rates, generations, turnament size, and compare performance.\n",
    "while finetuning hyperparameters, ensure that you print only the best cost for each hyperparameter combination.\n",
    "6. population size should be 1000, turnament size should be 10, crossover rate should be 0.8, mutation rate should be 0.1, generations should be 1000\n",
    "7. Track and plot the **convergence history** (e.g., best total distance per iteration).\n",
    "8. Ensure that constraints (such as fulfilling `rp` demand and valid location visits) are respected. Apply penalties for infeasible solutions in the fitness function.\n",
    "9. At the end, print and return:\n",
    "   - The best solution found (clearly, with structure and interpretation)\n",
    "   - The final tuned hyperparameters\n",
    "   - The convergence plot\n",
    "10. do not provide if __name__ == \"__main__\" block\n",
    "11. Ensure the code is syntactically correct and can be executed directly in a Python environment.\n",
    "\n",
    "Only output a **complete runnable Python script** enclosed in triple backticks (```), and nothing else.\n",
    "**Do NOT generate fake or random data. Use the `q_pi`, `rp`,`distance_matrix`, `product`, `locations` and `location_start` variables as provided.**\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=1, model=\"o4-mini\")\n",
    "\n",
    "# LLMChain\n",
    "metaheuristic_chain = code_gen_prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ef624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. **Classify the Problem**:\n",
    "#         - Identify the broad category this problem belongs to (e.g., TSP, VRP, Knapsack, p-median, Scheduling, etc.)\n",
    "\n",
    "#     2. **Identify Specific Variant**:\n",
    "#         - Determine if the problem is a special variant (e.g., Capacitated VRP, Time-window TSP, Multi-objective Knapsack, etc.)\n",
    "#         - Mention key constraints or special rules that define this variant.\n",
    "\n",
    "#     3. **Analyze Sub-variations (if any)**:\n",
    "#         - Highlight any further intricacies or domain-specific constraints that influence solution structure (e.g., precedence constraints, time dependencies, multiple depots, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf6453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "gene_representation_cot_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    *ROLE*: You are an expert in Genetic Algorithms (GA) and a logical thinker with a deep understanding of optimization problem-solving.\n",
    "\n",
    "    *INPUTS*: \n",
    "    Problem Description: {problem}\n",
    "\n",
    "    *TASK*: \n",
    "    Think step by step to develop a genetic encoding strategy for solving the above problem using Genetic Algorithms.\n",
    "    \n",
    "    Your goals are:\n",
    "    - To define a suitable genetic representation (chromosome structure)\n",
    "    - To devise a method for generating valid initial solutions\n",
    "\n",
    "    *THINKING STEPS*:\n",
    "\n",
    "    1. **Understand the Problem Type**:\n",
    "       - Classify the type of optimization problem (e.g., TSP, scheduling, assignment, knapsack, VRP, etc.)\n",
    "       - Identify any constraints or special rules involved.\n",
    "\n",
    "    2. **Design Genetic Representation**:\n",
    "       - Propose a chromosome structure (e.g., permutation, binary vector, integer encoding, real values, etc.)\n",
    "       - Define what each gene represents in context.\n",
    "       - Explain the domain/range of each gene and why the chosen encoding is appropriate.\n",
    "\n",
    "    3. **Handle Constraints in Encoding**:\n",
    "       - Are all encoded solutions feasible by default?\n",
    "       - If not, how will constraints be handled? (repair method, penalty, decoder, etc.)\n",
    "\n",
    "    4. **Generate Initial Population**:\n",
    "       - Describe how to construct the initial solutions (random, heuristic, hybrid)\n",
    "       - Ensure diversity and feasibility of initial solutions.\n",
    "\n",
    "    5. **Example** (Optional but helpful):\n",
    "       - Give an example of a chromosome and explain its meaning for the given problem.\n",
    "\n",
    "    Return your reasoning step-by-step. Make sure each step logically flows into the next.\n",
    "    \"\"\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "gene_representation_cot_chain = gene_representation_cot_prompt | llm\n",
    "\n",
    "\n",
    "# gene_representation_prompt = ChatPromptTemplate.from_template(\n",
    "#     \"\"\"\n",
    "#     *ROLE*: You are an expert in wrting consiously from the thought genereted by LLM\n",
    "\n",
    "#     *INPUTS*: \n",
    "#     Thought on how to represent gene and generate inital solution: {thought}\n",
    "\n",
    "#     **TASK**:\n",
    "#     consisly write final description of the thought given to you\n",
    "#     provide example so that it will helpfull for future where LLM will code it\n",
    "\n",
    "#     only provide description and example \n",
    "\n",
    "#     \"\"\"\n",
    "# )\n",
    "# llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "# gene_representation_chain = gene_representation_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossover_mutation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    *ROLE*: You are an expert in Genetic Algorithms (GA) and evolutionary computation, skilled at designing effective genetic operators for diverse optimization problems.\n",
    "\n",
    "    *INPUTS*: \n",
    "    Problem Description: {problem}\n",
    "    Genetic Representation: {representation}\n",
    "\n",
    "    *TASK*: \n",
    "    Think step by step to design suitable crossover and mutation operators for the above problem, given the specified genetic representation.\n",
    "\n",
    "    Your goals are:\n",
    "    - To define an appropriate crossover operator (with rationale and implementation details)\n",
    "    - To define an appropriate mutation operator (with rationale and implementation details)\n",
    "\n",
    "    *THINKING STEPS*:\n",
    "\n",
    "    1. **Analyze the Genetic Representation**:\n",
    "       - Describe the chromosome structure and gene types.\n",
    "       - Identify any constraints or dependencies among genes.\n",
    "\n",
    "    2. **Design Crossover Operator**:\n",
    "       - Propose a crossover method suitable for the representation (e.g., one-point, two-point, uniform, PMX, order, arithmetic, etc.)\n",
    "       - Explain how the operator works step-by-step.\n",
    "       - Discuss how feasibility is maintained (if relevant).\n",
    "       - Optionally, provide a small example.\n",
    "\n",
    "    3. **Design Mutation Operator**:\n",
    "       - Propose a mutation method suitable for the representation (e.g., bit flip, swap, inversion, random reset, Gaussian, etc.)\n",
    "       - Explain how the operator works step-by-step.\n",
    "       - Discuss how feasibility is maintained (if relevant).\n",
    "       - Optionally, provide a small example.\n",
    "\n",
    "    4. **Output Format**:\n",
    "       - Return your answer as a JSON dictionary with two keys: \"crossover\" and \"mutation\".\n",
    "       - Each key should contain a concise yet detailed explanation of the respective operator, including rationale, step-by-step description, and example if helpful.\n",
    "\n",
    "    *EXAMPLE OUTPUT*:\n",
    "    {{\n",
    "        \"crossover\": \"Order crossover (OX) is used for permutation-based chromosomes, such as TSP. It works by ... [details]\",\n",
    "        \"mutation\": \"Swap mutation is applied by randomly selecting two genes and swapping their positions. This helps ... [details]\"\n",
    "    }}\n",
    "\n",
    "    Think step by step and ensure your output is clear, logical, and formatted as specified.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "fitness_function_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    *ROLE*: You are an expert in Genetic Algorithms (GA) and optimization modeling, with a deep understanding of designing effective fitness functions for diverse problem domains.\n",
    "\n",
    "    *INPUTS*: \n",
    "    Problem Description: {problem}\n",
    "    Genetic Representation: {representation}\n",
    "\n",
    "    *TASK*: \n",
    "    Think step by step to design a suitable fitness function for evaluating solutions to the above problem, given the specified genetic representation.\n",
    "\n",
    "    Your goals are:\n",
    "    - To define a clear and appropriate fitness function\n",
    "    - To ensure the fitness function aligns with the problem objectives and constraints\n",
    "\n",
    "    *THINKING STEPS*:\n",
    "\n",
    "    1. **Understand the Problem Objective**:\n",
    "       - Clarify whether the problem is a maximization or minimization task.\n",
    "       - Identify the main goal (e.g., minimize cost, maximize profit, shortest path, etc.).\n",
    "\n",
    "    2. **Translate Objectives to Fitness**:\n",
    "       - Explain how the objective(s) will be quantified as a fitness value.\n",
    "       - If the problem is a minimization, describe how to convert it to a maximization (if needed).\n",
    "\n",
    "    3. **Handle Constraints**:\n",
    "       - Identify any constraints (hard or soft).\n",
    "       - Describe how constraint violations will be penalized or handled in the fitness evaluation.\n",
    "\n",
    "    4. **Implementation Details**:\n",
    "       - Provide a step-by-step outline or formula for calculating fitness.\n",
    "       - Optionally, give a small example calculation.\n",
    "\n",
    "    5. **Output Format**:\n",
    "       - Return your answer as a JSON dictionary with a single key: \"fitness\".\n",
    "       - The value should be a concise yet detailed explanation of the fitness function, including rationale, formula, and example if helpful.\n",
    "\n",
    "    *EXAMPLE OUTPUT*:\n",
    "    {{\n",
    "        \"fitness\": \"For the TSP, fitness is defined as the inverse of the total tour length: fitness = 1 / (total_distance + epsilon). This ensures shorter tours have higher fitness. Constraint violations (e.g., missing cities) are penalized by assigning a very low fitness.\"\n",
    "    }}\n",
    "\n",
    "    Think step by step and ensure your output is clear, logical, and formatted as specified.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "selection_operator_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    *ROLE*: You are an expert in Genetic Algorithms (GA) and evolutionary computation, skilled at designing robust selection mechanisms for population-based optimization.\n",
    "\n",
    "    *INPUTS*: \n",
    "    Problem Description: {problem}\n",
    "    Genetic Representation: {representation}\n",
    "    Fitness Function: {fitness}\n",
    "\n",
    "    *TASK*: \n",
    "    Think step by step to select and describe a suitable selection operator for the above problem, given the genetic representation and fitness function.\n",
    "\n",
    "    Your goals are:\n",
    "    - To choose an appropriate selection method (e.g., tournament, roulette wheel, rank-based, etc.)\n",
    "    - To explain how the operator works and why it fits the problem context\n",
    "\n",
    "    *THINKING STEPS*:\n",
    "\n",
    "    1. **Analyze Fitness Landscape**:\n",
    "       - Discuss the distribution and scaling of fitness values.\n",
    "       - Identify risks of premature convergence or loss of diversity.\n",
    "\n",
    "    2. **Choose Selection Method**:\n",
    "       - Propose a selection operator and justify your choice (e.g., tournament for noisy fitness, roulette for proportional selection, etc.).\n",
    "       - Explain how the method balances exploration and exploitation.\n",
    "\n",
    "    3. **Describe Operator Mechanism**:\n",
    "       - Provide a step-by-step description of how selection is performed.\n",
    "       - Optionally, include parameter choices (e.g., tournament size, selection pressure).\n",
    "\n",
    "    4. **Output Format**:\n",
    "       - Return your answer as a JSON dictionary with a single key: \"selection\".\n",
    "       - The value should be a concise yet detailed explanation of the selection operator, including rationale, step-by-step procedure, and example if helpful.\n",
    "\n",
    "    *EXAMPLE OUTPUT*:\n",
    "    {{\n",
    "        \"selection\": \"Tournament selection is used: randomly select k individuals from the population and choose the one with the highest fitness as a parent. Repeat as needed. Tournament size k=3 balances selection pressure and diversity.\"\n",
    "    }}\n",
    "\n",
    "    Think step by step and ensure your output is clear, logical, and formatted as specified.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d0eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gene_representation_cot_chain.invoke({'problem':problem})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1 = gene_representation_chain.invoke({'thought':gen.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38835dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae8f4e7-c828-48f9-8b03-5a599c9e97df",
   "metadata": {},
   "outputs": [],
   "source": [
    "code  = metaheuristic_chain.invoke({'formulation':formulation_text, \n",
    "                                    'problem_description':problem,\n",
    "                                    'given_data_set_description':given_data_set_description,\n",
    "                                    'initial_pop_description':gen.content,\n",
    "                                    'cross_over_description':cross_over_description,\n",
    "                                    'mutation_description':mutation_description,\n",
    "                                    'fitness_description':fitness_description,\n",
    "                                    'selection_description':selection_description})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df507439-068f-4eb5-b7e4-d05ebca15073",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = extract_python_code(code.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "ip = get_ipython()\n",
    "ip.set_next_input(code, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d16e1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product, combinations\n",
    "import copy\n",
    "import random\n",
    "random_number = random.choice(Customer_Order['waveNumber'].unique())\n",
    "rp, locations, location_start, products  = get_order_details(random_number)\n",
    "# Assumed to be provided in the environment:\n",
    "# q_pi: pandas DataFrame, index=products, columns=locations, entry = available qty\n",
    "# rp: dict, rp[p] = required qty for product p\n",
    "# distance_matrix: pandas DataFrame, square, index=locations, columns=locations\n",
    "# products: list of product IDs\n",
    "# locations: list of location IDs\n",
    "# location_start: starting location ID\n",
    "\n",
    "# Build valid location list for each product\n",
    "valid_locs = {}\n",
    "for p in products:\n",
    "    need = rp[p]\n",
    "    locs = [l for l in locations if q_pi.loc[p, l] >= need]\n",
    "    if not locs:\n",
    "        raise ValueError(f\"No feasible pick locations for product {p}\")\n",
    "    valid_locs[p] = locs\n",
    "\n",
    "# Decoder: from chromosome to route and cost\n",
    "def decode_and_cost(chromosome):\n",
    "    # chromosome: list of indices, one per product in products\n",
    "    # map to selected location IDs\n",
    "    selected = []\n",
    "    for gene, p in zip(chromosome, products):\n",
    "        locs = valid_locs[p]\n",
    "        if gene < 0 or gene >= len(locs):\n",
    "            # infeasible gene -> large penalty\n",
    "            return None, 1e12\n",
    "        selected.append(locs[gene])\n",
    "    # unique visits\n",
    "    visit = list(dict.fromkeys(selected))\n",
    "    route = [location_start]\n",
    "    unvisited = set(visit)\n",
    "    current = location_start\n",
    "    total = 0.0\n",
    "    # greedy nearest neighbor\n",
    "    while unvisited:\n",
    "        next_loc = min(unvisited, key=lambda x: distance_matrix.loc[current, x])\n",
    "        total += distance_matrix.loc[current, next_loc]\n",
    "        route.append(next_loc)\n",
    "        current = next_loc\n",
    "        unvisited.remove(next_loc)\n",
    "    # return to start\n",
    "    total += distance_matrix.loc[current, location_start]\n",
    "    route.append(location_start)\n",
    "    return route, total\n",
    "\n",
    "# Tournament selection\n",
    "def tournament_select(pop, fitnesses, t_size):\n",
    "    best = None\n",
    "    best_fit = float('inf')\n",
    "    for _ in range(t_size):\n",
    "        i = random.randrange(len(pop))\n",
    "        if fitnesses[i] < best_fit:\n",
    "            best_fit = fitnesses[i]\n",
    "            best = pop[i]\n",
    "    return best\n",
    "\n",
    "# Crossover: uniform\n",
    "def crossover(p1, p2):\n",
    "    size = len(p1)\n",
    "    c1, c2 = p1.copy(), p2.copy()\n",
    "    for i in range(size):\n",
    "        if random.random() < 0.5:\n",
    "            c1[i], c2[i] = c2[i], c1[i]\n",
    "    return c1, c2\n",
    "\n",
    "# Mutation: random reset\n",
    "def mutate(ind, m_rate):\n",
    "    size = len(ind)\n",
    "    child = ind.copy()\n",
    "    for i, p in enumerate(products):\n",
    "        if random.random() < m_rate:\n",
    "            child[i] = random.randrange(len(valid_locs[p]))\n",
    "    return child\n",
    "\n",
    "# Run GA for one hyperparameter setting\n",
    "def run_ga(pop_size, t_size, cx_rate, mut_rate, gens):\n",
    "    # init population\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        ind = [random.randrange(len(valid_locs[p])) for p in products]\n",
    "        population.append(ind)\n",
    "    # evaluate\n",
    "    fitnesses = []\n",
    "    for ind in population:\n",
    "        _, cost = decode_and_cost(ind)\n",
    "        fitnesses.append(cost)\n",
    "    best_hist = []\n",
    "    best_overall = None\n",
    "    best_cost = float('inf')\n",
    "    for gen in range(gens):\n",
    "        newpop = []\n",
    "        # elitism: carry best\n",
    "        idx = int(np.argmin(fitnesses))\n",
    "        newpop.append(population[idx])\n",
    "        while len(newpop) < pop_size:\n",
    "            p1 = tournament_select(population, fitnesses, t_size)\n",
    "            p2 = tournament_select(population, fitnesses, t_size)\n",
    "            if random.random() < cx_rate:\n",
    "                c1, c2 = crossover(p1, p2)\n",
    "            else:\n",
    "                c1, c2 = p1.copy(), p2.copy()\n",
    "            c1 = mutate(c1, mut_rate)\n",
    "            c2 = mutate(c2, mut_rate)\n",
    "            newpop.append(c1)\n",
    "            if len(newpop) < pop_size:\n",
    "                newpop.append(c2)\n",
    "        # eval newpop\n",
    "        population = newpop\n",
    "        fitnesses = []\n",
    "        for ind in population:\n",
    "            _, cost = decode_and_cost(ind)\n",
    "            fitnesses.append(cost)\n",
    "        cur_best = min(fitnesses)\n",
    "        best_hist.append(cur_best)\n",
    "        if cur_best < best_cost:\n",
    "            best_cost = cur_best\n",
    "            best_overall = population[int(np.argmin(fitnesses))]\n",
    "    return best_overall, best_cost, best_hist\n",
    "\n",
    "# Hyperparameter tuning grids (only one combination as specified)\n",
    "pop_sizes = [1000]\n",
    "t_sizes = [10]\n",
    "cx_rates = [0.8]\n",
    "mut_rates = [0.1]\n",
    "gens_list = [50]\n",
    "\n",
    "best_global = None\n",
    "best_params = None\n",
    "best_cost = float('inf')\n",
    "best_history = None\n",
    "\n",
    "# for pop_size, t_size, cx_rate, mut_rate, gens in product(pop_sizes, t_sizes, cx_rates, mut_rates, gens_list):\n",
    "#     print(f\"Testing params: pop={pop_size}, tour={t_size}, cx={cx_rate}, mut={mut_rate}, gen={gens}\")\n",
    "#     ind, cost, hist = run_ga(pop_size, t_size, cx_rate, mut_rate, gens)\n",
    "#     print(f\"Best cost: {cost:.2f}\")\n",
    "#     if cost < best_cost:\n",
    "#         best_cost = cost\n",
    "#         best_global = ind\n",
    "#         best_params = (pop_size, t_size, cx_rate, mut_rate, gens)\n",
    "#         best_history = hist\n",
    "\n",
    "# # Decode best solution\n",
    "# best_route, best_cost = decode_and_cost(best_global)\n",
    "# solution = {p: valid_locs[p][gene] for p, gene in zip(products, best_global)}\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\n===== Best Solution =====\")\n",
    "# print(\"Product -> Pick Location:\")\n",
    "# for p in products:\n",
    "#     print(f\"  {p} -> {solution[p]}\")\n",
    "# print(f\"Route: {best_route}\")\n",
    "# print(f\"Total distance: {best_cost:.2f}\")\n",
    "# print(\"\\n===== Tuned Hyperparameters =====\")\n",
    "# print(f\"Population size: {best_params[0]}\")\n",
    "# print(f\"Tournament size: {best_params[1]}\")\n",
    "# print(f\"Crossover rate: {best_params[2]}\")\n",
    "# print(f\"Mutation rate: {best_params[3]}\")\n",
    "# print(f\"Generations: {best_params[4]}\")\n",
    "\n",
    "# # Plot convergence\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.plot(best_history, label='Best Cost per Generation')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Total Distance')\n",
    "# plt.title('GA Convergence')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53989ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order.groupby('waveNumber')['quantity (units)'].sum().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cee940",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order.waveNumber.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c730b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order.creationDate = pd.to_datetime(Customer_Order.creationDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43521f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveNums_exact = []\n",
    "for wavenum in Customer_Order.waveNumber.unique():\n",
    "    rp, locations, location_start, products  = get_order_details(wavenum)\n",
    "    if len(locations)<50:\n",
    "        waveNums_exact.append(wavenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"waveNumless30.txt\", \"w\") as f:\n",
    "    for item in waveNums_exact:\n",
    "        f.write(str(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read list from file\n",
    "with open(\"waveNumless30.txt\", \"r\") as f:\n",
    "    waveNums_loaded = [float(line.strip()) for line in f] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e94e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order[Customer_Order['waveNumber'].isin(waveNums_loaded)].groupby(['waveNumber','Reference']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337dd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ref_counts = Customer_Order[\n",
    "    Customer_Order['waveNumber'].isin(waveNums_loaded)\n",
    "].groupby('waveNumber')['Reference'].nunique()\n",
    "\n",
    "# Filter waveNumbers with more than 5 unique references\n",
    "wave_numbers_unique_gt5 = unique_ref_counts[unique_ref_counts > 1]\n",
    "\n",
    "# Output the counts\n",
    "print(wave_numbers_unique_gt5)\n",
    "\n",
    "wave_numbers_unique_gt1 = unique_ref_counts[unique_ref_counts > 2].index\n",
    "\n",
    "# If you want to convert it to a list:\n",
    "wave_numbers_list = wave_numbers_unique_gt1.tolist()\n",
    "\n",
    "print(wave_numbers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import networkx as nx\n",
    "def solve_exact(P, L, rp, s, q_pi, c):\n",
    "    \n",
    "\n",
    "    L_all = L + [s] if s not in L else L.copy()\n",
    "\n",
    "    def subtour_elimination_cb(model, where):\n",
    "        if where == GRB.Callback.MIPSOL:\n",
    "            y_sol = model.cbGetSolution(y)\n",
    "            edges = [(i, j) for (i, j) in y_sol if y_sol[i, j] > 0.5]\n",
    "\n",
    "            G = nx.Graph()\n",
    "            G.add_edges_from(edges)\n",
    "            components = list(nx.connected_components(G))\n",
    "\n",
    "            for comp in components:\n",
    "                if s in comp or len(comp) < 2:\n",
    "                    continue\n",
    "                cut_edges = [(i, j) for i in comp for j in comp if i != j and (i, j) in y]\n",
    "                model.cbLazy(gp.quicksum(y[i, j] for i, j in cut_edges) <= len(comp) - 1)\n",
    "\n",
    "    M = sum(rp.values())\n",
    "    m = gp.Model(\"Product_Picking_Route_Optimization\")\n",
    "\n",
    "    z = m.addVars(L_all, vtype=GRB.BINARY, name=\"z\")  # location visited\n",
    "    y = m.addVars(L_all, L_all, vtype=GRB.BINARY, name=\"y\")  # travel\n",
    "\n",
    "    d_p = rp  # alias\n",
    "\n",
    "    # Objective: minimize total travel distance\n",
    "    m.setObjective(gp.quicksum(c.loc[l1, l2] * y[l1, l2] for l1 in L_all for l2 in L_all if l1 != l2), GRB.MINIMIZE)\n",
    "\n",
    "    # Demand fulfillment\n",
    "    for p in P:\n",
    "        m.addConstr(gp.quicksum(q_pi.loc[p, l] * z[l] for l in L) >= d_p[p], name=f\"demand_fulfillment_{p}\")\n",
    "\n",
    "    m.addConstr(z[s] == 1, name=\"start\")\n",
    "\n",
    "    for j in L:\n",
    "        m.addConstr(gp.quicksum(y[i, j] for i in L_all if i != j) == z[j], name=f\"flow_in_{j}\")\n",
    "    for i in L:\n",
    "        m.addConstr(gp.quicksum(y[i, j] for j in L_all if i != j) == z[i], name=f\"flow_out_{i}\")\n",
    "\n",
    "    m.setParam(\"LazyConstraints\", 1)\n",
    "    m.setParam(\"Threads\", 4)\n",
    "    m.setParam(\"MIPGap\", 0.01)\n",
    "\n",
    "    m.optimize(subtour_elimination_cb)\n",
    "\n",
    "    if m.status == GRB.OPTIMAL or m.status == GRB.TIME_LIMIT:\n",
    "        selected_routes = [(i, j) for i in L_all for j in L_all if i != j and y[i, j].x > 0.5]\n",
    "        route_dict = {i: j for i, j in selected_routes}\n",
    "\n",
    "        travel_path = [s]\n",
    "        while True:\n",
    "            current = travel_path[-1]\n",
    "            if current in route_dict:\n",
    "                next_node = route_dict[current]\n",
    "                travel_path.append(next_node)\n",
    "                if next_node == s:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return travel_path, m.objVal\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exact = {}\n",
    "\n",
    "for wavenum in wave_numbers_list:\n",
    "    rp, L, s, P = get_order_details(wavenum)\n",
    "    \n",
    "    route, objVal = solve_exact(P, L, rp, s, q_pi, distance_matrix)\n",
    "    \n",
    "    results_exact[wavenum] = {\n",
    "        \"route\": route,\n",
    "        \"objective_value\": objVal\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d9518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_results = pd.DataFrame([\n",
    "    {\"wavenum\": w, \"route\": v[\"route\"], \"objective_value\": v[\"objective_value\"]}\n",
    "    for w, v in results_exact.items()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff8b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e4715",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order[Customer_Order['waveNumber']==42118].loc[:,['Reference','quantity (units)']].groupby('Reference').sum().reset_index().rename(columns={'Reference':'Product ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09253fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ec8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp, L, s, P = get_order_details()\n",
    "    \n",
    "route, objVal = solve_exact(P, L, rp, s, q_pi, distance_matrix)\n",
    "\n",
    "results_exact[wavenum] = {\n",
    "    \"route\": route,\n",
    "    \"objective_value\": objVal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_code_string(code_string, global_vars=None):\n",
    "    \"\"\"\n",
    "    Executes the given code string in the global namespace and captures printed output.\n",
    "    Returns the printed output as a string.\n",
    "    \"\"\"\n",
    "    # Use provided globals or default to current globals\n",
    "    if global_vars is None:\n",
    "        global_vars = globals()\n",
    "    # Capture printed output\n",
    "    output_stream = StringIO()\n",
    "    original_stdout = sys.stdout\n",
    "    try:\n",
    "        sys.stdout = output_stream\n",
    "        exec(code_string, global_vars)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during execution: {e}\")\n",
    "    finally:\n",
    "        sys.stdout = original_stdout\n",
    "    result = output_stream.getvalue()\n",
    "    output_stream.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_start= 'CC-08'\n",
    "global_vars = {\n",
    "    'q_pi': q_pi,\n",
    "    'rp': rp,\n",
    "    'distance_matrix': distance_matrix,\n",
    "    'products': products,\n",
    "    'locations': locations,\n",
    "    'location_start': location_start,\n",
    "    # Also add built-ins and any modules you need:\n",
    "    '__builtins__': __builtins__,\n",
    "    'random': __import__('random'),\n",
    "    'np': __import__('numpy'),\n",
    "    'pd': __import__('pandas'),\n",
    "    # If you need matplotlib, import it as well:\n",
    "    'plt': __import__('matplotlib.pyplot', fromlist=['plt'])\n",
    "}\n",
    "execute_code_string(code,global_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15e467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp, locations, location_start, products = get_order_details(33169)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4222764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Assume the following variables are already defined in the environment:\n",
    "# q_pi            : pandas DataFrame, index=product IDs, columns=location IDs, values=available qty\n",
    "# rp              : dict, product ID -> required qty\n",
    "# distance_matrix : pandas DataFrame, index=location IDs, columns=location IDs\n",
    "# products        : list of product IDs\n",
    "# locations       : list of location IDs\n",
    "# location_start  : the start/end location ID (e.g., 'CC-08')\n",
    "\n",
    "# Precompute feasible pick locations per product\n",
    "random.seed = 42\n",
    "avail_locations = {\n",
    "    p: [l for l in locations if q_pi.loc[p, l] >= rp[p]]\n",
    "    for p in products\n",
    "}\n",
    "\n",
    "def init_population(pop_size):\n",
    "    avail_locations = {\n",
    "    p: [l for l in locations if q_pi.loc[p, l] >= rp[p]]\n",
    "    for p in products\n",
    "    }\n",
    "\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        prod_seq = products.copy()\n",
    "        random.shuffle(prod_seq)\n",
    "        gene_seq = []\n",
    "        for p in prod_seq:\n",
    "            locs = avail_locations[p] if avail_locations[p] else locations\n",
    "            gene_seq.append((p, random.choice(locs)))\n",
    "        population.append(gene_seq)\n",
    "    return population\n",
    "\n",
    "def fitness(individual):\n",
    "    \"\"\"Compute total travel distance + infeasibility penalty.\"\"\"\n",
    "    total = 0.0\n",
    "    prev = location_start\n",
    "    penalty = 0.0\n",
    "    PENALTY_FACTOR = 1000.0\n",
    "    for p, loc in individual:\n",
    "        total += distance_matrix.loc[prev, loc]\n",
    "        prev = loc\n",
    "        # penalty if not enough stock\n",
    "        avail = q_pi.loc[p, loc] if (p in q_pi.index and loc in q_pi.columns) else 0\n",
    "        if avail < rp[p]:\n",
    "            penalty += (rp[p] - avail) * PENALTY_FACTOR\n",
    "    total += distance_matrix.loc[prev, location_start]\n",
    "    return total + penalty\n",
    "\n",
    "def tournament_select(pop, fitnesses, k):\n",
    "    \"\"\"Select one individual by tournament of size k.\"\"\"\n",
    "    contestants = random.sample(range(len(pop)), k)\n",
    "    best = min(contestants, key=lambda i: fitnesses[i])\n",
    "    return pop[best]\n",
    "\n",
    "def crossover(parent1, parent2, rate):\n",
    "    \"\"\"Order Crossover (OX) on gene tuples (p,loc).\"\"\"\n",
    "    n = len(parent1)\n",
    "    if random.random() > rate:\n",
    "        return parent1.copy(), parent2.copy()\n",
    "    a, b = sorted(random.sample(range(n), 2))\n",
    "    def ox(p1, p2):\n",
    "        child = [None]*n\n",
    "        # copy slice from p1\n",
    "        child[a:b+1] = p1[a:b+1]\n",
    "        # fill from p2\n",
    "        p1_products = {g[0] for g in child[a:b+1]}\n",
    "        idx = (b+1) % n\n",
    "        for gene in p2[b+1:] + p2[:b+1]:\n",
    "            if gene[0] not in p1_products:\n",
    "                child[idx] = gene\n",
    "                idx = (idx + 1) % n\n",
    "        return child\n",
    "    return ox(parent1, parent2), ox(parent2, parent1)\n",
    "\n",
    "def mutate(individual, rate):\n",
    "    \"\"\"Swap two genes in the second half with probability rate.\"\"\"\n",
    "    if random.random() > rate:\n",
    "        return individual\n",
    "    n = len(individual)\n",
    "    half = n // 2\n",
    "    if(n>=5):\n",
    "        i, j = random.sample(range(half, n), 2)\n",
    "        individual[i], individual[j] = individual[j], individual[i]\n",
    "        return individual\n",
    "    elif(n>1):\n",
    "        i, j = random.sample(range(n),2)\n",
    "        individual[i],individual[j] = individual[j], individual[i]\n",
    "        return individual\n",
    "    else:\n",
    "        return individual\n",
    "\n",
    "def run_ga(pop_size, generations, tournament_size, crossover_rate, mutation_rate):\n",
    "    start_time = time.time()\n",
    "    pop = init_population(pop_size)\n",
    "    fitnesses = [fitness(ind) for ind in pop]\n",
    "    best_history = []\n",
    "    best_individual = None\n",
    "    best_fit = float('inf')\n",
    "    for gen in range(generations):\n",
    "        new_pop = []\n",
    "        # keep evolving until new population is full\n",
    "        while len(new_pop) < pop_size:\n",
    "            p1 = tournament_select(pop, fitnesses, tournament_size)\n",
    "            p2 = tournament_select(pop, fitnesses, tournament_size)\n",
    "            o1, o2 = crossover(p1, p2, crossover_rate)\n",
    "            o1 = mutate(o1, mutation_rate)\n",
    "            o2 = mutate(o2, mutation_rate)\n",
    "            new_pop.extend([o1, o2])\n",
    "        pop = new_pop[:pop_size]\n",
    "        fitnesses = [fitness(ind) for ind in pop]\n",
    "        current_best = min(fitnesses)\n",
    "        best_history.append(current_best)\n",
    "        if current_best < best_fit:\n",
    "            best_fit = current_best\n",
    "            best_individual = pop[fitnesses.index(current_best)]\n",
    "        end_time = time.time()\n",
    "    return best_individual, best_fit, best_history, end_time - start_time\n",
    "\n",
    "# Hyperparameter grid (for automated tuning)\n",
    "pop_sizes       = [4000]\n",
    "tournament_sizes= [10]\n",
    "crossover_rates = [0.9]\n",
    "mutation_rates  = [0.2]\n",
    "generations_list= [30]\n",
    "\n",
    "# results = []\n",
    "# for ps in pop_sizes:\n",
    "#     for ts in tournament_sizes:\n",
    "#         for cr in crossover_rates:\n",
    "#             for mr in mutation_rates:\n",
    "#                 for gens in generations_list:\n",
    "#                     print(f\"Running GA: pop={ps}, tour={ts}, cr={cr}, mr={mr}, gen={gens}\")\n",
    "#                     ind, fit, hist = run_ga(ps, gens, ts, cr, mr)\n",
    "#                     results.append({\n",
    "#                         'pop': ps, 'tour': ts, 'cr': cr, 'mr': mr, 'gens': gens,\n",
    "#                         'fitness': fit, 'individual': ind, 'history': hist\n",
    "#                     })\n",
    "\n",
    "# # Select best overall\n",
    "# best_run = min(results, key=lambda x: x['fitness'])\n",
    "# best_individual = best_run['individual']\n",
    "# best_fitness = best_run['fitness']\n",
    "# best_history = best_run['history']\n",
    "# best_params = {\n",
    "#     'population_size': best_run['pop'],\n",
    "#     'tournament_size': best_run['tour'],\n",
    "#     'crossover_rate': best_run['cr'],\n",
    "#     'mutation_rate': best_run['mr'],\n",
    "#     'generations': best_run['gens']\n",
    "# }\n",
    "\n",
    "# # Print best solution\n",
    "# print(\"\\nBest Genetic Algorithm Result\")\n",
    "# print(\"-----------------------------\")\n",
    "# print(f\"Total Distance (with penalties): {best_fitness:.2f}\")\n",
    "# print(\"Picking Route:\")\n",
    "# route = [location_start] + [loc for (_, loc) in best_individual] + [location_start]\n",
    "# for i in range(len(route)-1):\n",
    "#     print(f\"  {route[i]} -> {route[i+1]}  (d={distance_matrix.loc[route[i], route[i+1]]})\")\n",
    "# print(\"\\nProduct picks (product: location):\")\n",
    "# for p, loc in best_individual:\n",
    "#     print(f\"  {p} : {loc} (required {rp[p]}, available {q_pi.loc[p,loc]})\")\n",
    "\n",
    "# print(\"\\nBest Hyperparameters:\")\n",
    "# for k, v in best_params.items():\n",
    "#     print(f\"  {k}: {v}\")\n",
    "\n",
    "# # Plot convergence\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(best_history, label='Best Fitness')\n",
    "# plt.xlabel('Generation')\n",
    "# plt.ylabel('Fitness (Distance + Penalty)')\n",
    "# plt.title('GA Convergence History')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44286208",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = 1000\n",
    "ts= 10\n",
    "cr = 0.9\n",
    "mr = 0.1\n",
    "gens= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7669d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order[Customer_Order['waveNumber']==43175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06e5fbab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'T3NVTG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m rp, locations, location_start, products \u001b[38;5;241m=\u001b[39m get_order_details(\u001b[38;5;241m33902\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(f\"Running GA: pop={ps}, tour={ts}, cr={cr}, mr={mr}, gen={gens}\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print('waveNumber', wave_num)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m run_ga(ps, ts, cr, mr, gens)\n",
      "Cell \u001b[0;32mIn[35], line 89\u001b[0m, in \u001b[0;36mrun_ga\u001b[0;34m(pop_size, t_size, cx_rate, mut_rate, gens)\u001b[0m\n\u001b[1;32m     87\u001b[0m population \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pop_size):\n\u001b[0;32m---> 89\u001b[0m     ind \u001b[38;5;241m=\u001b[39m [random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;28mlen\u001b[39m(valid_locs[p])) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m products]\n\u001b[1;32m     90\u001b[0m     population\u001b[38;5;241m.\u001b[39mappend(ind)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# evaluate\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'T3NVTG'"
     ]
    }
   ],
   "source": [
    "rp, locations, location_start, products = get_order_details(33902)\n",
    "# print(f\"Running GA: pop={ps}, tour={ts}, cr={cr}, mr={mr}, gen={gens}\")\n",
    "# print('waveNumber', wave_num)\n",
    "run_ga(ps, ts, cr, mr, gens)\n",
    "# results.append({\n",
    "#     'waveNumber':wave_num, 'fitness': fit, 'individual': ind, 'history': hist\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b82c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9KHDG3': 7, 'APQKWK': 1, 'F29V5I': 4, 'K3YA1X': 12}\n",
      "{'CD1NU9': 18, 'SMMRK3': 6}\n",
      "{'05W6TK': 25, 'XUZJ74': 1}\n",
      "{'6M2FJM': 4, 'LXJQVG': 20}\n",
      "{'05W6TK': 1, 'V6K6JX': 22, 'XPZSZ1': 1}\n",
      "{'5P2MVG': 1, '8N10W9': 23}\n",
      "{'SMMRK3': 16, 'XUZJ74': 8}\n",
      "{'8N10W9': 2, 'I1KDJ0': 22}\n",
      "{'I1KDJ0': 13, 'LXJQVG': 11}\n",
      "{'05W6TK': 11, 'LXJQVG': 6}\n",
      "{'I1KDJ0': 10, 'WRRW1W': 14}\n"
     ]
    }
   ],
   "source": [
    "for wave_num in [42974, 42826, 42630, 42512, 42332, 42321, 42136, 41684, 41614,\n",
    "       41559, 41372]:\n",
    "    rp, locations, location_start, products = get_order_details(wave_num)\n",
    "    print(rp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c03438eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42974\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42826\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42630\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42512\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42332\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42321\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 42136\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 41684\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 41614\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 41559\n",
      "Running GA: pop=1000, tour=10, cr=0.9, mr=0.1, gen=30\n",
      "waveNumber 41372\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for wave_num in [42974, 42826, 42630, 42512, 42332, 42321, 42136, 41684, 41614,\n",
    "       41559, 41372]:\n",
    "    rp, locations, location_start, products = get_order_details(wave_num)\n",
    "    print(f\"Running GA: pop={ps}, tour={ts}, cr={cr}, mr={mr}, gen={gens}\")\n",
    "    print('waveNumber', wave_num)\n",
    "    ind, fit, hist, soltime = run_ga(ps, gens, ts, cr, mr)\n",
    "    results.append({\n",
    "        'waveNumber':wave_num, 'fitness': fit, 'individual': ind, 'history': hist, 'soltime': soltime\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d144e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_route_from_individual(individual, location_start='CC-08'):\n",
    "    \"\"\"\n",
    "    Convert an individual (list of (product, location) tuples) to a route string.\n",
    "    \n",
    "    Args:\n",
    "        individual: List of tuples like [(product1, location1), (product2, location2), ...]\n",
    "        location_start: Starting/ending location (default: 'CC-08')\n",
    "    \n",
    "    Returns:\n",
    "        String representation of the route\n",
    "    \"\"\"\n",
    "    # Extract just the locations from the individual\n",
    "    locations_in_route = [loc for _, loc in individual]\n",
    "    \n",
    "    # Build the complete route: start -> locations -> start\n",
    "    complete_route = [location_start] + locations_in_route + [location_start]\n",
    "    \n",
    "    # Join with arrows\n",
    "    route_string = \" -> \".join(complete_route)\n",
    "    \n",
    "    return route_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34c4fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df['route'] = df['individual'].apply(extract_route_from_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b50fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['individual', 'history'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebda45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_ga_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e638fda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9KHDG3', 'F-18-12'),\n",
       " ('F29V5I', 'F-20-12'),\n",
       " ('APQKWK', 'F-20-13'),\n",
       " ('K3YA1X', 'F-22-11')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['individual'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8065037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fitness'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fitness'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613aeb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p,i in best_individual:\n",
    "    if q_pi.loc[p,i]<=rp[p]:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Customer_Order.groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ff32a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume the following variables are already defined in the environment:\n",
    "# q_pi: pandas.DataFrame, index=product IDs, columns=location IDs, available quantities\n",
    "# rp: dict, required quantities per product\n",
    "# distance_matrix: pandas.DataFrame, distances between locations\n",
    "# products: list of product IDs\n",
    "# locations: list of location IDs\n",
    "# location_start: starting/ending location ID\n",
    "\n",
    "def generate_initial_population(pop_size):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        # assign each product to a valid location\n",
    "        loc_choice = {}\n",
    "        for p in products:\n",
    "            # only pick locations that have enough quantity\n",
    "            valid_locs = []\n",
    "            for l in locations:\n",
    "                x = q_pi.loc[p, l]\n",
    "                x = float(x)\n",
    "                if x < rp[p]:\n",
    "                    valid_locs.append(l)\n",
    "            if not valid_locs:\n",
    "                valid_locs = locations[:]  # fallback if none satisfy\n",
    "            loc_choice[p] = random.choice(valid_locs)\n",
    "        # create a random route order of products\n",
    "        prod_order = products[:]\n",
    "        random.shuffle(prod_order)\n",
    "        # individual is list of (product, location) in visit order\n",
    "        individual = [(p, loc_choice[p]) for p in prod_order]\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "def fitness(individual):\n",
    "    # sum distances along the route including return to start\n",
    "    total = 0.0\n",
    "    # from start to first\n",
    "    first_loc = individual[0][1]\n",
    "    total += distance_matrix.loc[location_start, first_loc]\n",
    "    # between consecutive\n",
    "    for i in range(len(individual)-1):\n",
    "        l1 = individual[i][1]\n",
    "        l2 = individual[i+1][1]\n",
    "        total += distance_matrix.loc[l1, l2]\n",
    "    # last back to start\n",
    "    last_loc = individual[-1][1]\n",
    "    total += distance_matrix.loc[last_loc, location_start]\n",
    "    # no feasibility penalty because we only chose valid locations\n",
    "    return total\n",
    "\n",
    "def tournament_selection(pop, fitnesses, k):\n",
    "    selected = []\n",
    "    pop_size = len(pop)\n",
    "    for _ in range(pop_size):\n",
    "        aspirants = random.sample(range(pop_size), k)\n",
    "        best = min(aspirants, key=lambda i: fitnesses[i])\n",
    "        selected.append(pop[best])\n",
    "    return selected\n",
    "\n",
    "def crossover(parent1, parent2, rate):\n",
    "    if random.random() > rate:\n",
    "        return parent1[:], parent2[:]\n",
    "    size = len(parent1)\n",
    "    # choose crossover points for order crossover\n",
    "    a, b = sorted(random.sample(range(size), 2))\n",
    "    # child1\n",
    "    segment1 = parent1[a:b]\n",
    "    leftover1 = [gene for gene in parent2 if gene[0] not in [g[0] for g in segment1]]\n",
    "    child1 = leftover1[:a] + segment1 + leftover1[a:]\n",
    "    # child2\n",
    "    segment2 = parent2[a:b]\n",
    "    leftover2 = [gene for gene in parent1 if gene[0] not in [g[0] for g in segment2]]\n",
    "    child2 = leftover2[:a] + segment2 + leftover2[a:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual, rate):\n",
    "    if random.random() > rate:\n",
    "        return individual\n",
    "    size = len(individual)\n",
    "    start = size // 2\n",
    "    # select two positions in second half and swap genes\n",
    "    i, j = random.sample(range(start, size), 2)\n",
    "    ind = individual[:]\n",
    "    ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "def run_ga(pop_size, cx_rate, mut_rate, generations, tour_size):\n",
    "    pop = generate_initial_population(pop_size)\n",
    "    best_hist = []\n",
    "    best_ind = None\n",
    "    best_fit = float('inf')\n",
    "    for gen in range(generations):\n",
    "        # evaluate\n",
    "        fits = [fitness(ind) for ind in pop]\n",
    "        # record best\n",
    "        min_idx = int(np.argmin(fits))\n",
    "        if fits[min_idx] < best_fit:\n",
    "            best_fit = fits[min_idx]\n",
    "            best_ind = pop[min_idx][:]\n",
    "        best_hist.append(best_fit)\n",
    "        # selection\n",
    "        sel = tournament_selection(pop, fits, tour_size)\n",
    "        # generate next\n",
    "        nxt = []\n",
    "        for i in range(0, pop_size, 2):\n",
    "            p1 = sel[i]\n",
    "            p2 = sel[(i+1) % pop_size]\n",
    "            c1, c2 = crossover(p1, p2, cx_rate)\n",
    "            nxt.append(mutate(c1, mut_rate))\n",
    "            if len(nxt) < pop_size:\n",
    "                nxt.append(mutate(c2, mut_rate))\n",
    "        pop = nxt\n",
    "    return best_ind, best_fit, best_hist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Hyperparameter tuning grid\n",
    "    pop_sizes = [1000]\n",
    "    cx_rates = [0.8]\n",
    "    mut_rates = [0.01]\n",
    "    gens = [1000]\n",
    "    tour_size = 3\n",
    "\n",
    "    best_overall = None\n",
    "    best_params = None\n",
    "    best_value = float('inf')\n",
    "    best_history = None\n",
    "\n",
    "    for ps in pop_sizes:\n",
    "        for cr in cx_rates:\n",
    "            for mr in mut_rates:\n",
    "                for g in gens:\n",
    "                    ind, val, hist = run_ga(ps, cr, mr, g, tour_size)\n",
    "                    print(f\"Tested PS={ps}, CX={cr}, MU={mr}, GEN={g}: BestDist={val:.2f}\")\n",
    "                    if val < best_value:\n",
    "                        best_value = val\n",
    "                        best_overall = ind\n",
    "                        best_params = {'pop_size': ps, 'cx_rate': cr, 'mut_rate': mr, 'generations': g}\n",
    "                        best_history = hist\n",
    "\n",
    "    # Final report\n",
    "    print(\"\\n=== Best Solution Found ===\")\n",
    "    print(f\"Method: Genetic Algorithm\")\n",
    "    print(f\"Hyperparameters: {best_params}\")\n",
    "    print(f\"Total Distance: {best_value:.2f}\")\n",
    "    print(\"Route (product -> location):\")\n",
    "    for p, l in best_overall:\n",
    "        print(f\"  {p} -> {l}\")\n",
    "    # Convergence plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(best_history, marker='o', linestyle='-')\n",
    "    plt.title(\"GA Convergence: Best Distance per Generation\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fcc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_point[support_point[\"labels\"]=='CC-08']['pa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac87456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_point[support_point[\"labels\"]=='CC-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pi.loc['WRRW1W',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "float(q_pi.loc['AKP0A7', locations[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c444792",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeCorrectionAgentUsingChain:\n",
    "    def __init__(self, chain, max_iterations=3):\n",
    "        self.chain = chain\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def run(self, formulation):\n",
    "        iteration = 0\n",
    "        current_formulation = formulation\n",
    "        response = self.chain.invoke({'formulation': current_formulation})\n",
    "        code = response.content if hasattr(response, 'content') else response\n",
    "        code = extract_python_code(code)\n",
    "        error = None\n",
    "        \n",
    "\n",
    "        while iteration < self.max_iterations:\n",
    "            # Step 1: Generate code using the chain\n",
    "            response = self.chain.invoke({'formulation': current_formulation})\n",
    "            code = response.content if hasattr(response, 'content') else response\n",
    "            code = extract_python_code(code)\n",
    "\n",
    "            # Step 2: Try to execute the generated code\n",
    "            try:\n",
    "                # exec_globals = {\n",
    "                #     'q_pi': q_pi,\n",
    "                #     'rp': rp,\n",
    "                #     'distance_matrix': distance_matrix,\n",
    "                #     'products': products,\n",
    "                #     'locations': locations,\n",
    "                #     'np': __import__('numpy'),\n",
    "                #     'plt': __import__('matplotlib.pyplot')\n",
    "                # }\n",
    "                exec(code)\n",
    "                error = None\n",
    "                break  # Success: exit the loop\n",
    "            except Exception as e:\n",
    "                error = str(e)\n",
    "                # Step 3: Reflect error back to the LLM by updating the formulation\n",
    "                current_formulation += f\"\\n# Error encountered: {error}\\n\"\n",
    "                iteration += 1\n",
    "\n",
    "        return code, error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b13e06",
   "metadata": {},
   "source": [
    "# Code correction agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Correction prompt template\n",
    "feedback_prompt = PromptTemplate(\n",
    "    input_variables=[\"code\", \"error\"],\n",
    "    template=\"\"\"\n",
    "You are an expert Python programmer and code reviewer.\n",
    "\n",
    "Below is a Python script that failed with an error. \n",
    "You are provided the following data objects already defined in memory:\n",
    "- `q_pi`: A pandas DataFrame with product IDs as rows and location IDs as columns. `q_pi.loc[p][l]` gives the quantity of product `p` available at location `l`.\n",
    "- `rp`: dict with product IDs as keys and required quantities as values. `rp[p]` gives the total quantity required for product `p`.\n",
    "- `distance_matrix`: A square DataFrame with location IDs as both rows and columns, representing the distance between locations.\n",
    "- `products`: A list of product IDs that need to be picked.\n",
    "-`locations`: A list of location IDs where products can be picked.\n",
    "-`location_start`: str The starting location for the picking route. \n",
    "\n",
    "\n",
    "--- CODE ---\n",
    "{code}\n",
    "--- ERROR ---\n",
    "{error}\n",
    "for your reference only Here is the problem and its formulation for which this code of meta-huristic {algoName} is written\n",
    "----Problem Description----\n",
    "{problem}\n",
    "----formulation----\n",
    "{formulation}\n",
    "--- END ---\n",
    "\n",
    "Please analyze the code and the error message, then provide a reasoning on why code is failing and how to fix it.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4.1\")\n",
    "feedback_chain = feedback_prompt | llm\n",
    "\n",
    "correction_prompt = PromptTemplate(\n",
    "    input_variables=[\"code\", \"error\", \"feedback\"],\n",
    "    template=\"\"\"\n",
    "You are an expert Python programmer and code reviewer.\n",
    "\n",
    "\n",
    "\n",
    "You are provided the following data objects already defined in memory:\n",
    "- `q_pi`: A pandas DataFrame with product IDs as rows and location IDs as columns. `q_pi.loc[p][l]` gives the quantity of product `p` available at location `l`.\n",
    "- `rp`: dict with product IDs as keys and required quantities as values. `rp[p]` gives the total quantity required for product `p`.\n",
    "- `distance_matrix`: A square DataFrame with location IDs as both rows and columns, representing the distance between locations.\n",
    "- `products`: A list of product IDs that need to be picked.\n",
    "-`locations`: A list of location IDs where products can be picked.\n",
    "-`location_start`: str The starting location for the picking route. \n",
    "\n",
    "Below is a Python script that failed with an error & feedback on how to fix it.\n",
    "--- CODE ---\n",
    "{code}\n",
    "--- ERROR ---\n",
    "{error}\n",
    "----FEEDBACK---\n",
    "{feedback}\n",
    "\n",
    "Here is the problem and its formulation for which this code of meta-huristic {algoName} is written\n",
    "----Problem Description----\n",
    "{problem}\n",
    "----formulation----\n",
    "{formulation}\n",
    "--- END ---\n",
    "\n",
    "Please analyze the code, the error message, and the feedback provided, then rewrite the code to fix the error.\n",
    "and lookafter the end result should not be hampered while correcting the error\n",
    "Make sure the new code is runnable and corrects the issues mentioned in the feedback.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4.1\")\n",
    "correction_chain = correction_prompt | llm\n",
    "\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "# The SequentialChain will first run feedback_chain, then pass its output (feedback)\n",
    "# along with code and error to code_correction_chain.\n",
    "# code_correction_chain = SequentialChain(\n",
    "#     chains=[feedback_chain, correction_chain],\n",
    "#     input_variables=[\"code\", \"error\"],\n",
    "#     output_variables=[\"corrected_code\"],\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "code_correction_chain = feedback_chain | correction_chain\n",
    "\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_code_correction_agent(code, code_correction_chain, max_iterations=3):\n",
    "    # Step 1: Generate initial code\n",
    "    for iteration in range(max_iterations):\n",
    "        try:\n",
    "            exec_globals = {\n",
    "                'q_pi': q_pi,\n",
    "                'rp': rp,\n",
    "                'distance_matrix': distance_matrix,\n",
    "                'products': products,\n",
    "                'locations': locations,\n",
    "                'np': __import__('numpy'),\n",
    "                'plt': __import__('matplotlib.pyplot'),\n",
    "                'location_start': location_start,\n",
    "                '__name__': '__main__'  # Ensure the code runs in the main context\n",
    "            }\n",
    "            exec(code, exec_globals)\n",
    "            print(f\"Success on iteration {iteration+1}\")\n",
    "            return code, None\n",
    "        except Exception as e:\n",
    "            error = str(e)\n",
    "            print(f\"Error on iteration {iteration+1}: {error}\")\n",
    "            # Use the code correction chain to fix the code\n",
    "            print(code)\n",
    "            feedback_response = feedback_chain.invoke({'code': code, 'error': error})\n",
    "            feedback = feedback_response.content \n",
    "            print(f\"Feedback received: {feedback}\")\n",
    "            correction_response = code_correction_chain.invoke({\n",
    "                'code': code,\n",
    "                'error': error,\n",
    "                'feedback': feedback\n",
    "            })\n",
    "            code = correction_response.content \n",
    "            code = extract_python_code(code )\n",
    "    return code, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4640d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "def execute_code_string(code_string, global_vars):\n",
    "    \"\"\"\n",
    "    Executes code_string in global_vars namespace,\n",
    "    captures printed output and exceptions.\n",
    "    Returns (success_flag, output_or_error).\n",
    "    \"\"\"\n",
    "    output_stream = StringIO()\n",
    "    original_stdout = sys.stdout\n",
    "    try:\n",
    "        sys.stdout = output_stream\n",
    "        exec(code_string, global_vars)\n",
    "        sys.stdout = original_stdout\n",
    "        output = output_stream.getvalue()\n",
    "        output_stream.close()\n",
    "        return True, output\n",
    "    except Exception as e:\n",
    "        sys.stdout = original_stdout\n",
    "        output_stream.close()\n",
    "        return False, str(e)\n",
    "\n",
    "def run_code_correction_agent(code, code_correction_chain, feedback_chain, max_iterations=3):\n",
    "    for iteration in range(max_iterations):\n",
    "        exec_globals = {\n",
    "            'q_pi': q_pi,\n",
    "            'rp': rp,\n",
    "            'distance_matrix': distance_matrix,\n",
    "            'products': products,\n",
    "            'locations': locations,\n",
    "            'np': __import__('numpy'),\n",
    "            'plt': __import__('matplotlib.pyplot'),\n",
    "            'random': __import__('random'),\n",
    "            'pd': __import__('pandas'),\n",
    "            'location_start': location_start,\n",
    "            '__name__': '__main__'\n",
    "        }\n",
    "        success, output_or_error = execute_code_string(code, exec_globals)\n",
    "        if success:\n",
    "            print(f\"Success on iteration {iteration+1}\")\n",
    "            print(\"Execution output:\\n\", output_or_error)\n",
    "            return code, None\n",
    "        else:\n",
    "            error = output_or_error\n",
    "            print(f\"Error on iteration {iteration+1}: {error}\")\n",
    "            print(\"Current code:\\n\", code)\n",
    "            \n",
    "            # Use the feedback chain to get feedback on the error\n",
    "            feedback_response = feedback_chain.invoke({'code': code, 'error': error})\n",
    "            feedback = feedback_response.content\n",
    "            print(f\"Feedback received: {feedback}\")\n",
    "            \n",
    "            # Use the code correction chain to generate corrected code\n",
    "            correction_response = code_correction_chain.invoke({\n",
    "                'code': code,\n",
    "                'error': error,\n",
    "                'feedback': feedback\n",
    "            })\n",
    "            code = correction_response.content\n",
    "            \n",
    "            # Optional: extract python code if correction chain returns markdown or text\n",
    "            code = extract_python_code(code)\n",
    "            \n",
    "    # After max iterations, return last code and last error\n",
    "    return code, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "def execute_code_string(code_string, global_vars=None):\n",
    "    \"\"\"\n",
    "    Executes a code string and returns a dict with:\n",
    "    - 'status': True if successful, False if error occurred\n",
    "    - 'output': printed output or error traceback\n",
    "    \"\"\"\n",
    "    if global_vars is None:\n",
    "        global_vars = globals()\n",
    "\n",
    "    output_stream = StringIO()\n",
    "    original_stdout = sys.stdout\n",
    "\n",
    "    try:\n",
    "        sys.stdout = output_stream\n",
    "        exec(code_string, global_vars)\n",
    "        status = True\n",
    "    except Exception:\n",
    "        traceback.print_exc(file=output_stream)\n",
    "        status = False\n",
    "    finally:\n",
    "        sys.stdout = original_stdout\n",
    "\n",
    "    output = output_stream.getvalue()\n",
    "    output_stream.close()\n",
    "\n",
    "    return {\n",
    "        \"status\": status,\n",
    "        \"output\": output\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77526158",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = execute_code_string(\"\"\"\n",
    "print(\"Hello\")\n",
    "\"\"\")\n",
    "\n",
    "if result[\"status\"]:\n",
    "    print(\"✅ Code executed successfully:\\n\", result[\"output\"])\n",
    "else:\n",
    "    print(\"❌ Code execution failed:\\n\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7744683",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = metaheuristic_chain.invoke({'formulation':formulation_text, \n",
    "                                    'problem_description':problem,\n",
    "                                    'given_data_set_description':given_data_set_description,\n",
    "                                    'initial_pop_description':initial_pop_description,\n",
    "                                    'cross_over_description':cross_over_description,\n",
    "                                    'mutation_description':mutation_description,\n",
    "                                    'fitness_description':fitness_description,\n",
    "                                    'selection_description':selection_description})\n",
    "code = response.content if hasattr(response, 'content') else response\n",
    "code = extract_python_code(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d7414",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_code, final_error = run_code_correction_agent(\n",
    "    code = code,\n",
    "    code_correction_chain=code_correction_chain,\n",
    "    max_iterations=5\n",
    ")\n",
    "\n",
    "if final_error is None:\n",
    "    print(\"Final code executed successfully!\")\n",
    "else:\n",
    "    print(\"Failed after retrievs. Last error:\", final_error)\n",
    "print(final_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_globals = {\n",
    "    'q_pi': q_pi,\n",
    "    'rp': rp,\n",
    "    'distance_matrix': distance_matrix,\n",
    "    'products': products,\n",
    "    'locations': locations,\n",
    "    'np': __import__('numpy'),\n",
    "    'plt': __import__('matplotlib.pyplot'),\n",
    "    'location_start': location_start,\n",
    "    \"__name__\" : \"__main__\"\n",
    "}\n",
    "try:\n",
    "    exec(final_code, exec_globals)\n",
    "except Exception as e:\n",
    "    print(f\"Final code execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ff12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "ip = get_ipython()\n",
    "ip.set_next_input(final_code, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume the following are defined in memory:\n",
    "# q_pi: pandas DataFrame, rows=product IDs, cols=location IDs, quantities available\n",
    "# rp: dict, required quantities per product\n",
    "# distance_matrix: pandas DataFrame, rows&cols=location IDs, travel distances\n",
    "# products: list of product IDs\n",
    "# locations: list of location IDs\n",
    "# location_start: starting/ending location ID\n",
    "\n",
    "def generate_population(pop_size):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        # location genome: one pick-location per product\n",
    "        loc_genome = []\n",
    "        for p in products:\n",
    "            # prefer locations that satisfy the full requirement\n",
    "            avail = [l for l in locations if q_pi.loc[p, l] >= rp[p]]\n",
    "            if not avail:\n",
    "                # otherwise any location with some stock\n",
    "                avail = [l for l in locations if q_pi.loc[p, l] > 0]\n",
    "            if not avail:\n",
    "                # fallback to any location\n",
    "                avail = locations[:]\n",
    "            loc_genome.append(random.choice(avail))\n",
    "        # order genome: a random permutation of product indices\n",
    "        order_genome = list(range(len(products)))\n",
    "        random.shuffle(order_genome)\n",
    "        population.append({'loc': loc_genome, 'order': order_genome})\n",
    "    return population\n",
    "\n",
    "def pmx_crossover(o1, o2):\n",
    "    \"\"\" Partially Mapped Crossover for permutations o1, o2 \"\"\"\n",
    "    n = len(o1)\n",
    "    c1, c2 = sorted(random.sample(range(n), 2))\n",
    "    child = [None]*n\n",
    "    # copy slice from o1\n",
    "    child[c1:c2] = o1[c1:c2]\n",
    "    # map the rest from o2\n",
    "    for i in range(c1, c2):\n",
    "        v = o2[i]\n",
    "        if v not in child:\n",
    "            pos = i\n",
    "            while True:\n",
    "                v2 = o1[pos]\n",
    "                pos = o2.index(v2)\n",
    "                if child[pos] is None:\n",
    "                    child[pos] = v\n",
    "                    break\n",
    "    # fill remaining\n",
    "    for i in range(n):\n",
    "        if child[i] is None:\n",
    "            child[i] = o2[i]\n",
    "    return child\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    n = len(parent1['loc'])\n",
    "    # single-point crossover on location genome\n",
    "    cp = random.randint(1, n-1)\n",
    "    child_loc = parent1['loc'][:cp] + parent2['loc'][cp:]\n",
    "    # PMX crossover on order genome\n",
    "    child_order = pmx_crossover(parent1['order'], parent2['order'])\n",
    "    return {'loc': child_loc, 'order': child_order}\n",
    "\n",
    "def mutate(ind):\n",
    "    n = len(ind['loc'])\n",
    "    # swap two pick-locations in the second half\n",
    "    half = n // 2\n",
    "    if n - half >= 2:\n",
    "        i, j = random.sample(range(half, n), 2)\n",
    "        ind['loc'][i], ind['loc'][j] = ind['loc'][j], ind['loc'][i]\n",
    "    # swap two positions in the order genome\n",
    "    i, j = random.sample(range(n), 2)\n",
    "    ind['order'][i], ind['order'][j] = ind['order'][j], ind['order'][i]\n",
    "\n",
    "def evaluate_fitness(ind, max_dist):\n",
    "    # build full route: start -> picks -> start\n",
    "    route = [location_start] + [ind['loc'][i] for i in ind['order']] + [location_start]\n",
    "    dist = 0.0\n",
    "    for a, b in zip(route[:-1], route[1:]):\n",
    "        dist += distance_matrix.loc[a, b]\n",
    "    # penalty for unmet demand\n",
    "    penalty = 0.0\n",
    "    for idx, p in enumerate(products):\n",
    "        loc = ind['loc'][idx]\n",
    "        if q_pi.loc[p, loc] < rp[p]:\n",
    "            penalty += max_dist * 10\n",
    "    return dist + penalty\n",
    "\n",
    "def tournament_select(pop, fitnesses, k):\n",
    "    contenders = random.sample(list(zip(pop, fitnesses)), k)\n",
    "    # select the individual with minimal fitness\n",
    "    best = min(contenders, key=lambda x: x[1])\n",
    "    return best[0]\n",
    "\n",
    "def genetic_algorithm():\n",
    "    # Hyperparameter grids for automatic tuning\n",
    "    pop_sizes    = [1000]\n",
    "    gen_counts   = [1000]\n",
    "    cross_rates  = [0.8]\n",
    "    mut_rates    = [0.01]\n",
    "    tourn_sizes  = [3]\n",
    "\n",
    "    # precompute a large distance for penalty scaling\n",
    "    max_dist = distance_matrix.values.max()\n",
    "\n",
    "    overall_best = None\n",
    "    overall_best_fit = float('inf')\n",
    "    overall_best_hist = []\n",
    "    overall_params = None\n",
    "\n",
    "    # grid search over hyperparameters\n",
    "    for pop_size in pop_sizes:\n",
    "        for generations in gen_counts:\n",
    "            for cr in cross_rates:\n",
    "                for mr in mut_rates:\n",
    "                    for ts in tourn_sizes:\n",
    "                        # initialize population\n",
    "                        pop = generate_population(pop_size)\n",
    "                        hist = []\n",
    "                        # evolve\n",
    "                        for gen in range(generations):\n",
    "                            # evaluate\n",
    "                            fits = [evaluate_fitness(ind, max_dist) for ind in pop]\n",
    "                            best_idx = int(np.argmin(fits))\n",
    "                            best_fit = fits[best_idx]\n",
    "                            hist.append(best_fit)\n",
    "                            # create new population\n",
    "                            new_pop = []\n",
    "                            while len(new_pop) < pop_size:\n",
    "                                p1 = tournament_select(pop, fits, ts)\n",
    "                                p2 = tournament_select(pop, fits, ts)\n",
    "                                if random.random() < cr:\n",
    "                                    c1 = crossover(p1, p2)\n",
    "                                    c2 = crossover(p2, p1)\n",
    "                                else:\n",
    "                                    c1 = {'loc': p1['loc'][:], 'order': p1['order'][:]}\n",
    "                                    c2 = {'loc': p2['loc'][:], 'order': p2['order'][:]}\n",
    "                                new_pop.append(c1)\n",
    "                                if len(new_pop) < pop_size:\n",
    "                                    new_pop.append(c2)\n",
    "                            # mutation\n",
    "                            for ind in new_pop:\n",
    "                                if random.random() < mr:\n",
    "                                    mutate(ind)\n",
    "                            pop = new_pop\n",
    "                        # final evaluation\n",
    "                        fits = [evaluate_fitness(ind, max_dist) for ind in pop]\n",
    "                        best_idx = int(np.argmin(fits))\n",
    "                        best_fit = fits[best_idx]\n",
    "                        if best_fit < overall_best_fit:\n",
    "                            overall_best_fit = best_fit\n",
    "                            overall_best = pop[best_idx]\n",
    "                            overall_best_hist = hist\n",
    "                            overall_params = {\n",
    "                                'pop_size': pop_size,\n",
    "                                'generations': generations,\n",
    "                                'crossover_rate': cr,\n",
    "                                'mutation_rate': mr,\n",
    "                                'tournament_size': ts\n",
    "                            }\n",
    "    # report\n",
    "    print(\"Method: Genetic Algorithm for Warehouse Picking Route\")\n",
    "    print(\"Tuned Hyperparameters:\", overall_params)\n",
    "    print(f\"Best total distance (with penalties): {overall_best_fit:.2f}\")\n",
    "    # interpret solution\n",
    "    print(\"\\nBest picking plan:\")\n",
    "    # determine visiting sequence with products\n",
    "    seq = overall_best['order']\n",
    "    for step, idx in enumerate(seq, start=1):\n",
    "        p = products[idx]\n",
    "        l = overall_best['loc'][idx]\n",
    "        print(f\" Step {step}: pick product '{p}' from location '{l}'\")\n",
    "    print(f\" Return to start '{location_start}' at step {len(seq)+1}\")\n",
    "\n",
    "    # convergence plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(overall_best_hist, marker='o', label='Best Fitness')\n",
    "    plt.title(\"GA Convergence History\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Best Fitness (Distance + Penalty)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # for reproducibility\n",
    "    random.seed(0)\n",
    "    genetic_algorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985bd0e",
   "metadata": {},
   "source": [
    "# exact gurobi implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5794b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp, locations, location_start, products  = get_order_details(43175)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc9a82d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-12-02\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'CC-08'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CC-08'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 65\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Constraints\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 1. Demand fulfillment\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m P:\n\u001b[0;32m---> 65\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(gp\u001b[38;5;241m.\u001b[39mquicksum(q_pi\u001b[38;5;241m.\u001b[39mloc[p, l]\u001b[38;5;241m*\u001b[39mz[l] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m L)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m d_p[p], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand_fulfillment_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# for p in P:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     m.addConstr(gp.quicksum(x[l, p] for l in L) == d_p[p], name=f\"demand_{p}\")\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#             name=f\"flow_{l}\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#         )z\u001b[39;00m\n\u001b[1;32m     94\u001b[0m m\u001b[38;5;241m.\u001b[39maddConstr(z[s]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32msrc/gurobipy/_helpers.pyx:41\u001b[0m, in \u001b[0;36mgurobipy._helpers.quicksum\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[22], line 65\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Constraints\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# 1. Demand fulfillment\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m P:\n\u001b[0;32m---> 65\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(gp\u001b[38;5;241m.\u001b[39mquicksum(q_pi\u001b[38;5;241m.\u001b[39mloc[p, l]\u001b[38;5;241m*\u001b[39mz[l] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m L)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m d_p[p], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand_fulfillment_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# for p in P:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     m.addConstr(gp.quicksum(x[l, p] for l in L) == d_p[p], name=f\"demand_{p}\")\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#             name=f\"flow_{l}\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#         )z\u001b[39;00m\n\u001b[1;32m     94\u001b[0m m\u001b[38;5;241m.\u001b[39maddConstr(z[s]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4214\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n\u001b[1;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4638\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4633\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[1;32m   4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CC-08'"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Sets\n",
    "P = products\n",
    "L = locations\n",
    "s = location_start\n",
    "L_all = L\n",
    "L_all.append(s)\n",
    "\n",
    "def subtour_elimination_cb(model, where):\n",
    "    if where == GRB.Callback.MIPSOL:\n",
    "        print(\"BRO FIUND\")\n",
    "        # Get the solution values\n",
    "        y_sol = model.cbGetSolution(y)\n",
    "        \n",
    "        # Build the graph\n",
    "        edges = [(i, j) for (i, j) in y_sol if y_sol[i, j] > 0.5]\n",
    "        \n",
    "        # Find connected components (subtours)\n",
    "        import networkx as nx\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(edges)\n",
    "        components = list(nx.connected_components(G))\n",
    "\n",
    "        # Enforce: only one connected component allowed (complete tour)\n",
    "        for comp in components:\n",
    "            if s in comp:\n",
    "                continue  # skip the component containing the start node\n",
    "\n",
    "            if len(comp) < 2:\n",
    "                continue  # no subtour to eliminate\n",
    "\n",
    "            # Add lazy constraint to eliminate this subtour\n",
    "            cut_edges = [(i, j) for i in comp for j in comp if i != j and (i, j) in y]\n",
    "            print(cut_edges)\n",
    "            model.cbLazy(gp.quicksum(y[i, j] for i, j in cut_edges) <= len(comp) - 1)\n",
    "\n",
    "\n",
    "\n",
    "# Parameters\n",
    "d_p = rp\n",
    "c = distance_matrix\n",
    "\n",
    "# Big-M for linking constraints\n",
    "M = sum(rp.values())\n",
    "\n",
    "# Create model\n",
    "# Create model\n",
    "m = gp.Model(\"Product_Picking_Route_Optimization\")\n",
    "\n",
    "# Decision Variables\n",
    "# x = m.addVars(L, P, vtype=GRB.INTEGER, name=\"x\", lb=0)  # quantity picked\n",
    "z = m.addVars(L_all, vtype=GRB.BINARY, name=\"z\")  # location visited\n",
    "y = m.addVars(L_all, L_all, vtype=GRB.BINARY, name=\"y\")  # travel\n",
    "# u = m.addVars(L, vtype=GRB.CONTINUOUS, name=\"u\", ub=len(L)+1)  # for subtour elimination\n",
    "\n",
    "# Objective: Minimize total distance\n",
    "m.setObjective(gp.quicksum(c.loc[l1, l2] * y[l1, l2] for l1 in L for l2 in L if l1 != l2), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "# 1. Demand fulfillment\n",
    "\n",
    "for p in P:\n",
    "    m.addConstr(gp.quicksum(q_pi.loc[p, l]*z[l] for l in L)>= d_p[p], name=f\"demand_fulfillment_{p}\")\n",
    "\n",
    "\n",
    "# for p in P:\n",
    "#     m.addConstr(gp.quicksum(x[l, p] for l in L) == d_p[p], name=f\"demand_{p}\")\n",
    "\n",
    "# # 2. Cannot pick more than available\n",
    "# for l in L:\n",
    "#     for p in P:\n",
    "#         m.addConstr(x[l, p] <= q_pi.loc[p, l], name=f\"supply_{l}_{p}\")\n",
    "\n",
    "# 3. Link pick quantity and visit\n",
    "# for l in L:\n",
    "#     m.addConstr(gp.quicksum(x[l, p] for p in P) <= M * z[l], name=f\"link_pick_visit_{l}\")\n",
    "\n",
    "# 4. Start from s\n",
    "# m.addConstr(gp.quicksum(y[s, l] for l in L if l != s) == 1, name=\"start_from_s\")\n",
    "\n",
    "# 5. End at s\n",
    "# m.addConstr(gp.quicksum(y[l, s] for l in L if l != s) == 1, name=\"end_at_s\")\n",
    "\n",
    "# 6. Flow conservation\n",
    "# for l in L:\n",
    "#     if l != s:\n",
    "#         m.addConstr(\n",
    "#             gp.quicksum(y[l1, l] for l1 in L if l1 != l) == gp.quicksum(y[l, l2] for l2 in L if l2 != l),\n",
    "#             name=f\"flow_{l}\"\n",
    "#         )z\n",
    "\n",
    "m.addConstr(z[s]==1, name=\"start\")\n",
    "\n",
    "for j in L:\n",
    "    m.addConstr(\n",
    "        gp.quicksum(y[i, j] for i in L if (i != j)) == z[j],\n",
    "        name=f\"flow_{j}\"\n",
    "    )\n",
    "for i in L:\n",
    "    m.addConstr(\n",
    "        gp.quicksum(y[i,j] for j in L if (i!=j))==z[i],\n",
    "        name=f'flow_{j}_{i}'\n",
    "    )\n",
    "\n",
    "# 7. Subtour elimination (MTZ)\n",
    "# L_no_s = [l for l in L if l != s]\n",
    "# for l1 in L_no_s:\n",
    "#     for l2 in L_no_s:\n",
    "#         if l1 != l2:\n",
    "#             m.addConstr(\n",
    "#                 u[l1] - u[l2] + len(L) * y[l1, l2] <= len(L) - 1,\n",
    "#                 name=f\"subtour_{l1}_{l2}\"\n",
    "#             )\n",
    "\n",
    "m.update()\n",
    "print(m.NumConstrs)\n",
    "# Optimize\n",
    "m.setParam(\"LazyConstraints\", 1)\n",
    "m.setParam(\"Threads\", 4)      # parallelism\n",
    "m.setParam(\"MIPGap\",0.01)\n",
    "m.optimize(subtour_elimination_cb)\n",
    "\n",
    "\n",
    "# Extract results (optional)\n",
    "if m.status == GRB.OPTIMAL:\n",
    "    selected_routes = [(l1, l2) for l1 in L for l2 in L if l1 != l2 and y[l1, l2].x > 0.5]\n",
    "    # picked_quantities = {(l, p): x[l, p].x for l in L for p in P if x[l, p].x > 0.01}\n",
    "    visited_locations = [l for l in L if z[l].x > 0.5]\n",
    "    print(\"Selected travel path:\", selected_routes)\n",
    "    # print(\"Picked quantities:\", picked_quantities)\n",
    "    print(\"Visited locations:\", visited_locations)\n",
    "    route_dict = {i: j for i, j in selected_routes}\n",
    "\n",
    "    # Start from location_start 's' and follow the route\n",
    "    travel_path = [s]\n",
    "    while True:\n",
    "        current = travel_path[-1]\n",
    "        if current in route_dict:\n",
    "            next_node = route_dict[current]\n",
    "            travel_path.append(next_node)\n",
    "            if next_node == s:\n",
    "                break  # completed the loop\n",
    "        else:\n",
    "            print(\"⚠️ Route is broken or incomplete.\")\n",
    "            break\n",
    "\n",
    "    print(\"📍 Ordered travel route:\")\n",
    "    print(\" → \".join(travel_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7a1104f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Duplicate keys in Model.addVars()'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(L, P, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, lb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# quantity picked\u001b[39;00m\n\u001b[1;32m     23\u001b[0m z \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(L, vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mBINARY, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# location visited\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m y \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(L_all, L_all, vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mBINARY, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# travel\u001b[39;00m\n\u001b[1;32m     25\u001b[0m u \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(L, vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mCONTINUOUS, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# for subtour elimination\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Objective: Minimize total distance\u001b[39;00m\n",
      "File \u001b[0;32msrc/gurobipy/_model.pyx:3267\u001b[0m, in \u001b[0;36mgurobipy._model.Model.addVars\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Duplicate keys in Model.addVars()'"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "\n",
    "# Sets\n",
    "P = products\n",
    "L = locations\n",
    "s = location_start\n",
    "L_all = L + [s]  # include start location\n",
    "\n",
    "# Parameters\n",
    "d_p = rp\n",
    "c = distance_matrix\n",
    "\n",
    "# Big-M for linking constraints\n",
    "M = sum(rp.values())\n",
    "\n",
    "# Create model\n",
    "m = gp.Model(\"Product_Picking_Route_Optimization\")\n",
    "\n",
    "# Decision Variables\n",
    "x = m.addVars(L, P, name=\"x\", lb=0)  # quantity picked\n",
    "z = m.addVars(L, vtype=GRB.BINARY, name=\"z\")  # location visited\n",
    "y = m.addVars(L_all, L_all, vtype=GRB.BINARY, name=\"y\")  # travel\n",
    "u = m.addVars(L, vtype=GRB.CONTINUOUS, name=\"u\")  # for subtour elimination\n",
    "\n",
    "# Objective: Minimize total distance\n",
    "m.setObjective(gp.quicksum(c.loc[l1, l2] * y[l1, l2] for l1 in L for l2 in L if l1 != l2), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "# 1. Demand fulfillment\n",
    "for p in P:\n",
    "    m.addConstr(gp.quicksum(x[l, p] for l in L) == d_p[p], name=f\"demand_{p}\")\n",
    "\n",
    "# 2. Cannot pick more than available\n",
    "for l in L:\n",
    "    for p in P:\n",
    "        m.addConstr(x[l, p] <= q_pi.loc[p, l], name=f\"supply_{l}_{p}\")\n",
    "\n",
    "# 3. Link pick quantity and visit\n",
    "for l in L:\n",
    "    m.addConstr(gp.quicksum(x[l, p] for p in P) <= M * z[l], name=f\"link_pick_visit_{l}\")\n",
    "\n",
    "# 4. Start from s\n",
    "m.addConstr(gp.quicksum(y[s, l] for l in L if l != s) == 1, name=\"start_from_s\")\n",
    "\n",
    "# 5. End at s\n",
    "m.addConstr(gp.quicksum(y[l, s] for l in L if l != s) == 1, name=\"end_at_s\")\n",
    "\n",
    "# 6. Flow conservation\n",
    "for l in L:\n",
    "    if l != s:\n",
    "        m.addConstr(\n",
    "            gp.quicksum(y[l1, l] for l1 in L if l1 != l) == gp.quicksum(y[l, l2] for l2 in L if l2 != l),\n",
    "            name=f\"flow_{l}\"\n",
    "        )\n",
    "\n",
    "# 7. Subtour elimination (MTZ)\n",
    "L_no_s = [l for l in L if l != s]\n",
    "for l1 in L_no_s:\n",
    "    for l2 in L_no_s:\n",
    "        if l1 != l2:\n",
    "            m.addConstr(\n",
    "                u[l1] - u[l2] + len(L) * y[l1, l2] <= len(L) - 1,\n",
    "                name=f\"subtour_{l1}_{l2}\"\n",
    "            )\n",
    "m.setParam(\"LazyConstraints\", 1)\n",
    "m.setParam(\"TimeLimit\", 1200)  # 10 minutes\n",
    "m.setParam(\"Threads\", 4)      # parallelism\n",
    "\n",
    "# Optimize\n",
    "m.optimize(subtour_elimination_cb)\n",
    "\n",
    "\n",
    "# Extract results (optional)\n",
    "if m.status == GRB.OPTIMAL:\n",
    "    selected_routes = [(l1, l2) for l1 in L for l2 in L if l1 != l2 and y[l1, l2].x > 0.5]\n",
    "    picked_quantities = {(l, p): x[l, p].x for l in L for p in P if x[l, p].x > 0.01}\n",
    "    visited_locations = [l for l in L if z[l].x > 0.5]\n",
    "    print(\"Selected travel path:\", selected_routes)\n",
    "    print(\"Picked quantities:\", picked_quantities)\n",
    "    print(\"Visited locations:\", visited_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9336ef59",
   "metadata": {},
   "source": [
    "# Smart GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f567afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from typing import List, Tuple, Dict\n",
    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "import re\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "from typing import List, Tuple, TypedDict\n",
    "\n",
    "class Individual(TypedDict):\n",
    "    individual: List[Tuple[str, str]]\n",
    "\n",
    "class OffspringResponse(TypedDict):\n",
    "    new_offsprings: List[Individual]\n",
    "\n",
    "import json\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "import json\n",
    "import re\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from typing import Any\n",
    "\n",
    "class OffspringResponseParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> Any:\n",
    "        try:\n",
    "            # Extract JSON-like portion using regex\n",
    "            match = re.search(r\"\\{[\\s\\S]*?\\}\", text)\n",
    "            if not match:\n",
    "                raise ValueError(\"No JSON-like structure found\")\n",
    "\n",
    "            json_str = match.group()\n",
    "\n",
    "            # Fix single quotes → double quotes\n",
    "            json_str = json_str.replace(\"'\", '\"')\n",
    "\n",
    "            # Replace tuple (a, b) with list [\"a\", \"b\"]\n",
    "            json_str = re.sub(r'\\(\\s*\"(.*?)\"\\s*,\\s*\"(.*?)\"\\s*\\)', r'[\"\\1\", \"\\2\"]', json_str)\n",
    "\n",
    "            # Optional: validate brackets in \"individual\": [...]\n",
    "            json_str = re.sub(r'\"individual\":\\s*\\[([^\\]]*?)\\](?!,|\\s*\\})', r'\"individual\": [\\1]', json_str)\n",
    "\n",
    "            # Parse to Python dict\n",
    "            return json.loads(json_str)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to parse LLM output: {e}\")\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "# crossover_prompt_template = ChatPromptTemplate.from_template(\n",
    "#       \"\"\"\n",
    "# You are a genetic algorithm expert.\n",
    "\n",
    "# Each individual is a mapping from products to locations where they can be picked from. For example:\n",
    "\n",
    "# Lower the cost of the new individuals compared to the current population.\n",
    "# - Product families:\n",
    "#   - p1: (l1, l2, l3)\n",
    "#   - p2: (l4, l5, l6)\n",
    "#   - p3: (l7, l8, l9)\n",
    "\n",
    "# - Example individuals:\n",
    "#   - [(p1, l1), (p2, l4), (p3, l7)]\n",
    "#   - [(p2, l5), (p1, l2), (p3, l8)]\n",
    "#   - [(p1, l3), (p2, l6), (p3, l9)]\n",
    "\n",
    "# ### Location Encoding Format:\n",
    "\n",
    "# Warehouse location IDs follow the pattern `A-CC-XY`, where:\n",
    "# - `A`  = aisle identifier (e.g., \"J\")\n",
    "# - `CC` = compartment number (e.g., \"10\")\n",
    "# - `X`  = vertical level (e.g., \"2\" = level 2)\n",
    "# - `Y`  = position within that compartment (e.g., \"1\" = first location)\n",
    "\n",
    "# Example: `\"J-10-21\"` → Aisle J, 10th compartment, level 2, 1st position\n",
    "\n",
    "# These location codes help identify **spatial patterns** — such as products being picked from the same aisle, nearby compartments, or similar vertical levels — which may result in lower total travel distance.\n",
    "\n",
    "# ⛔ **Do not invent new location codes.**\n",
    "# ✅ **You may use this structure to identify location similarity patterns and generate new combinations that stay close in space.**\n",
    "\n",
    "# you are given two parents individuals and you have to perform crossover on them to generate new individuals that are better fit.\n",
    "# The **current population** with their costs is given below (lower cost = higher fitness): \n",
    "# #parent 1\n",
    "# {parent1}\n",
    "# #parent 2\n",
    "# {parent2}\n",
    "# ---\n",
    "\n",
    "# Think step-by step and generate new individuals via crossover that are better fit. \n",
    "# for example:\n",
    "# parent 1: [(p1, 'A-14-11'), (p2, 'B-16-12'), (p3, 'A-14-13')] 100\n",
    "# parent 2: [(p1, 'A-14-12'), (p2, 'B-16-11'), (p3, 'C-14-14')] 200\n",
    "\n",
    "# C is far from A & B so collecting p3 from A-14-13 might be more optimal and keeping p1 and p3 sequencely reduce unnesesary travel to A asile again\n",
    "# child 1: [(p1,A-14-11)],(p2, B-16-11), (p3, A-14-13)] \n",
    "# child 2: [(p1,A-14-11)], (p3, A-14-13), (p2, B-16-11)]\n",
    "# ### OUTPUT FORMAT (strict):\n",
    "\n",
    "# ```json\n",
    "# {{\n",
    "#   \"new_offsprings\": [\n",
    "#     {{\"individual\": [[\"p1\", \"l1\"], [\"p2\", \"l4\"], [\"p3\", \"l7\"]]}},\n",
    "#     {{\"individual\": [[\"p2\", \"l5\"], [\"p1\", \"l2\"], [\"p3\", \"l8\"]]}},\n",
    "#   ]\n",
    "# }}```\n",
    "\n",
    "# **STRICT INSTRUCTIONS**:\n",
    "#          - Do not include instructions or explanations in the output.\n",
    "#          - lower the cost higher the fitness of the individuals\n",
    "#          - as per the analysis of the patterns in the current population, generate new individuals via crossover that are better fit.\n",
    "#          - Do not generate new locations for products that are not present in the current population.\n",
    "# \"\"\"    \n",
    "# )\n",
    "\n",
    "crossover_prompt_template = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a genetic algorithm expert with expert in doing crossover smarlty after analysing the parents\n",
    "\n",
    "Each individual is a mapping from products to locations where they can be picked from. For example:\n",
    "\n",
    "Lower the cost of the new individuals compared to the current population.\n",
    "- Product families:\n",
    "  - p1: (l1, l2, l3)\n",
    "  - p2: (l4, l5, l6)\n",
    "  - p3: (l7, l8, l9)\n",
    "\n",
    "- Example individuals:\n",
    "  - [(p1, l1), (p2, l4), (p3, l7)]\n",
    "  - [(p2, l5), (p1, l2), (p3, l8)]\n",
    "  - [(p1, l3), (p2, l6), (p3, l9)]\n",
    "\n",
    "### Location Encoding Format:\n",
    "\n",
    "Warehouse location IDs follow the pattern `A-CC-XY`, where:\n",
    "- `A`  = aisle identifier (e.g., \"J\")\n",
    "- `CC` = compartment number (e.g., \"10\")\n",
    "- `X`  = vertical level (e.g., \"2\" = level 2)\n",
    "- `Y`  = position within that compartment (e.g., \"1\" = first location)\n",
    "\n",
    "Example: `\"J-10-21\"` → Aisle J, 10th compartment, level 2, 1st position\n",
    "\n",
    "These location codes help identify **spatial patterns** — such as products being picked from the same aisle, nearby compartments, or similar vertical levels — which may result in lower total travel distance.\n",
    "\n",
    "⛔ **Do not invent new location codes.**\n",
    "✅ **You may use this structure to identify location similarity patterns and generate new combinations that stay close in space.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The **current population** with their costs is given below (lower cost = higher fitness):\n",
    "\n",
    "{current_population}\n",
    "\n",
    "##NO of OFF-SPRINGS NEED TO BE GENERATED##\n",
    "no of off-springs should be \n",
    "{noOfOffSprings}\n",
    "\n",
    "##Cover all the products given below in offsprings\n",
    "{products}\n",
    "---\n",
    "\n",
    "Your task:\n",
    "1. Use only the product-location combinations present in the current population (no new locations).\n",
    "3. output \n",
    "2. Ensure the output is valid JSON and strictly matches the format shown below.\n",
    "4. (p1,l1) means product p1 is picked from location l1, and so on. so do not generate new locations for products that are not present in the current population.\n",
    "5. ensure new individuals have all the products present in the current populations\n",
    "6. Perform crossover on this population to generate new, potentially better offspring.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### OUTPUT FORMAT (strict):\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"new_offsprings\": [\n",
    "    {{\"individual\": [[\"p1\", \"l1\"], [\"p2\", \"l4\"], [\"p3\", \"l7\"]]}},\n",
    "    {{\"individual\": [[\"p2\", \"l5\"], [\"p1\", \"l2\"], [\"p3\", \"l8\"]]}},\n",
    "    {{\"individual\": [[\"p1\", \"l3\"], [\"p2\", \"l6\"], [\"p3\", \"l9\"]]}},\n",
    "    {{\"individual\": [[\"p3\", \"l8\"], [\"p2\", \"l4\"], [\"p1\", \"l1\"]]}}\n",
    "  ]\n",
    "}}```\n",
    "\n",
    "**STRICT INSTRUCTIONS**:\n",
    "        - generate at least {noOfOffSprings} number of off-springs\n",
    "         - Do not include instructions or explanations in the output.\n",
    "         - lower the cost higher the fitness of the individuals\n",
    "         - as per the analysis of the patterns in the current population, generate new individuals via crossover that are better fit.\n",
    "         - Do not generate new locations for products that are not present in the current population.\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# # Define the prompt template for smart crossover\n",
    "# crossover_prompt_template = ChatPromptTemplate.from_template(\n",
    "# \"\"\"You are a genetic algorithm expert. \n",
    "     \n",
    "#      1. representation of population \n",
    "#     family p1 represents the all the locations where product p1 is available let assume (l1, l2, l3)\n",
    "#     family p2 represents the all the locations where product p2 is available lets assume (l4, l5, l6)\n",
    "#     family p3 represents the all the locations where product p3 is available lets assume (l7, l8, l9)\n",
    "#     etc. \n",
    "#     now from this individual solution can represented as in initial population are \n",
    "#     1. p1: l1 p2: l4 p3: l7 and so on \n",
    "#     2. p2: l5 p1: l2 p3: l8 and so on\n",
    "#     3. p1: l3 p2: l6 p3 :l9 and so on\n",
    "#     4.p3: l8 p2: l4 p1: l1 and so on\n",
    "    \n",
    "#     here is the current population of individuals with their fitness:\n",
    "#     {current_population}\n",
    "\n",
    "#     you will be given population of individuals with thier cost and you need to perform crossover operation on them and have to generate new offspring individuals that might be the better fit .\n",
    "#     you have to analyse the current population and generate new individuals only\n",
    "#     you have to mutate the individuals also smartly (rate of mutation should be low)\n",
    "#     you have to return the new population in defined format\n",
    "#     Do not generate new locations for products that are not present in the current population. \n",
    "     \n",
    "#      OUTPUT FORMAT requirements:\n",
    "#      json \n",
    "#      {{\n",
    "#          \"new_offsprings\": \n",
    "#              {{\"individual\": [(p1,l1) (p2, l) (p3, l7)]}},\n",
    "#              {{\"individual\": [(p2,l5) (p1, l) (p3, l8)]}},\n",
    "#              {{\"individual\": [(p1,l3) (p2, l) (p3, l9)]}},\n",
    "#              {{\"individual\": [(p3,l8) (p2, l) (p1, l1)]}}\n",
    "#          ]\n",
    "#      }}\n",
    "    \n",
    "     \n",
    "#      **STRICT INSTRUCTIONS**:\n",
    "#         - Do not include instructions or explanations in the output.\n",
    "#         - lower the cost higher the fitness of the individuals\n",
    "#         - as per the analysis of the patterns in the current population, generate new individuals via crossover that are better fit.\n",
    "#         - Do not generate new locations for products that are not present in the current population.\n",
    "#      \"\"\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(temperature=1, model=\"o4-mini\")\n",
    "\n",
    "# Create the LLMChain\n",
    "smart_crossover_chain = crossover_prompt_template | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_initial_population(pop_size):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        # assign each product to a valid location\n",
    "        loc_choice = {}\n",
    "        for p in products:\n",
    "            # only pick locations that have enough quantity\n",
    "            valid_locs = []\n",
    "            for l in locations:\n",
    "                x = q_pi.loc[p, l]\n",
    "                x = float(x)\n",
    "                if x < rp[p]:\n",
    "                    valid_locs.append(l)\n",
    "            if not valid_locs:\n",
    "                valid_locs = locations[:]  # fallback if none satisfy\n",
    "            loc_choice[p] = random.choice(valid_locs)\n",
    "        # create a random route order of products\n",
    "        prod_order = products[:]\n",
    "        random.shuffle(prod_order)\n",
    "        # individual is list of (product, location) in visit order\n",
    "        individual = [(p, loc_choice[p]) for p in prod_order]\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "def fitness(individual):\n",
    "    # sum distances along the route including return to start\n",
    "    total = 0.0\n",
    "    # from start to first\n",
    "    first_loc = individual[0][1]\n",
    "    total += distance_matrix.loc[location_start, first_loc]\n",
    "    # between consecutive\n",
    "    for i in range(len(individual)-1):\n",
    "        l1 = individual[i][1]\n",
    "        l2 = individual[i+1][1]\n",
    "        total += distance_matrix.loc[l1, l2]\n",
    "    # last back to start\n",
    "    last_loc = individual[-1][1]\n",
    "    total += distance_matrix.loc[last_loc, location_start]\n",
    "    # no feasibility penalty because we only chose valid locations\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 3\n",
    "initial_pop = generate_initial_population(pop_size)\n",
    "initial_pop_fitness = [fitness(ind) for ind in initial_pop]\n",
    "for i in range(pop_size):\n",
    "    initial_pop[i] = {'individual': initial_pop[i], 'fitness': initial_pop_fitness[i]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ada67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = smart_crossover_chain.invoke({'parent1':initial_pop[0], 'parent2':initial_pop[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eaabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2282737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pop = generate_initial_population(pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3489c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f95fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "message.content\n",
    "\n",
    "match = re.search(r'```json\\s*(.*?)\\s*```', message.content, re.DOTALL)\n",
    "if match:\n",
    "    json_str = match.group(1)\n",
    "\n",
    "    # Step 2: Replace tuple-style parentheses with list-style brackets\n",
    "    json_str = json_str.replace(\"(\", \"[\").replace(\")\", \"]\")\n",
    "\n",
    "    # Step 3: Parse the cleaned string\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        print(\"Extracted Data:\")\n",
    "        # print(json.dumps(data, indent=2))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON parsing failed:\", e)\n",
    "else:\n",
    "    print(\"No JSON block found.\")\n",
    "\n",
    "# After loading the data using json.loads(...)\n",
    "# Convert the inner lists to tuples\n",
    "\n",
    "for offspring in data[\"new_offsprings\"]:\n",
    "    offspring[\"individual\"] = [tuple(pair) for pair in offspring[\"individual\"]]\n",
    "\n",
    "# Now it's a list of dicts, each with a list of tuples\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"new_offsprings\"][0]['individual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_initial_population(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80255c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class LivePlot:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "\n",
    "    def __call__(self, gen, value):\n",
    "        self.history.append(value)\n",
    "        clear_output(wait=True)  # Only needed in Jupyter\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(self.history, marker='o')\n",
    "        plt.title(f\"Live GA Convergence Plot (Gen {gen})\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Best Distance\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        time.sleep(0.1)  # Small pause for rendering\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     pop_sizes = [15]\n",
    "#     cx_rates = [0.9]\n",
    "#     mut_rates = [0.01]\n",
    "#     gens = [10]\n",
    "#     tour_size = 3\n",
    "\n",
    "#     best_overall = None\n",
    "#     best_params = None\n",
    "#     best_value = float('inf')\n",
    "#     best_history = None\n",
    "\n",
    "#     for ps in pop_sizes:\n",
    "#         for mr in mut_rates:\n",
    "#             for cr in cx_rates:\n",
    "#                 for g in gens:\n",
    "#                     live_plot = LivePlot()\n",
    "#                     ind, val, hist = run_ga(ps, cr, mr, g, tour_size, callback=live_plot)\n",
    "#                     if val < best_value:\n",
    "#                         best_value = val\n",
    "#                         best_overall = ind\n",
    "#                         best_params = {'pop_size': ps, 'mut_rate': mr, 'generations': g}\n",
    "#                         best_history = hist\n",
    "\n",
    "#     print(\"\\n=== Best Solution Found ===\")\n",
    "#     print(f\"Method: Genetic Algorithm\")\n",
    "#     print(f\"Hyperparameters: {best_params}\")\n",
    "#     print(f\"Total Distance: {best_value:.2f}\")\n",
    "#     print(\"Route (product -> location):\")\n",
    "#     for p, l in best_overall:\n",
    "#         print(f\"  {p} -> {l}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed34135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume the following variables are already defined in the environment:\n",
    "# q_pi: pandas.DataFrame, index=product IDs, columns=location IDs, available quantities\n",
    "# rp: dict, required quantities per product\n",
    "# distance_matrix: pandas.DataFrame, distances between locations\n",
    "# products: list of product IDs\n",
    "# locations: list of location IDs\n",
    "# location_start: starting/ending location ID\n",
    "\n",
    "def generate_initial_population(pop_size):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        # assign each product to a valid location\n",
    "        loc_choice = {}\n",
    "        for p in products:\n",
    "            # only pick locations that have enough quantity\n",
    "            valid_locs = []\n",
    "            for l in locations:\n",
    "                x = q_pi.loc[p, l]\n",
    "                x = float(x)\n",
    "                if x > rp[p]:\n",
    "                    valid_locs.append(l)\n",
    "            if not valid_locs:\n",
    "                valid_locs = locations[:]  # fallback if none satisfy\n",
    "            loc_choice[p] = random.choice(valid_locs)\n",
    "        # create a random route order of products\n",
    "        prod_order = products[:]\n",
    "        random.shuffle(prod_order)\n",
    "        # individual is list of (product, location) in visit order\n",
    "        individual = [(p, loc_choice[p]) for p in prod_order]\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "def pop_eval(pop, gene_size):\n",
    "    valid_pop = []\n",
    "    for individual in pop:\n",
    "        valid = True\n",
    "        if len(individual) != gene_size:\n",
    "            valid = False\n",
    "        for p, l in individual:\n",
    "            # Ensure keys exist and quantities are sufficient\n",
    "            try:\n",
    "                if q_pi.loc[p, l] < rp[p]:\n",
    "                    valid = False\n",
    "                    break\n",
    "            except KeyError:\n",
    "                valid = False\n",
    "                break\n",
    "\n",
    "        if valid:\n",
    "            valid_pop.append(individual)\n",
    "\n",
    "    return valid_pop\n",
    "\n",
    "def fitness(individual):\n",
    "    # sum distances along the route including return to start\n",
    "    total = 0.0\n",
    "    # from start to first\n",
    "    first_loc = individual[0][1]\n",
    "    total += distance_matrix.loc[location_start, first_loc]\n",
    "    # between consecutive\n",
    "    for i in range(len(individual)-1):\n",
    "        l1 = individual[i][1]\n",
    "        l2 = individual[i+1][1]\n",
    "        total += distance_matrix.loc[l1, l2]\n",
    "    # last back to start\n",
    "    last_loc = individual[-1][1]\n",
    "    total += distance_matrix.loc[last_loc, location_start]\n",
    "    # no feasibility penalty because we only chose valid locations\n",
    "    return total\n",
    "\n",
    "def tournament_selection(pop, fitnesses, k):\n",
    "    selected = []\n",
    "    pop_size = len(pop)\n",
    "    for _ in range(pop_size):\n",
    "        aspirants = random.sample(range(pop_size), k)\n",
    "        best = min(aspirants, key=lambda i: fitnesses[i])\n",
    "        selected.append(pop[best])\n",
    "    return selected\n",
    "\n",
    "def smart_crossover(current_population, cr_rate, pop_size):\n",
    "    noOfOffSprings = cr_rate*pop_size\n",
    "    result = smart_crossover_chain.invoke({'current_population': current_population,'noOfOffSprings':noOfOffSprings, 'products':products})\n",
    "    print(result.content)\n",
    "    match = re.search(r'```json\\s*(.*?)\\s*```', result.content, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "\n",
    "        # Step 2: Replace tuple-style parentheses with list-style brackets\n",
    "        json_str = json_str.replace(\"(\", \"[\").replace(\")\", \"]\")\n",
    "        # Step 3: Parse the cleaned string\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            print(\"Extracted Data:\")\n",
    "            print(json.dumps(data, indent=2))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON parsing failed:\", e)\n",
    "    else:\n",
    "        print(\"No JSON block found.\")\n",
    "\n",
    "    # After loading the data using json.loads(...)\n",
    "    # Convert the inner lists to tuples\n",
    "\n",
    "    for offspring in data[\"new_offsprings\"]:\n",
    "        offspring[\"individual\"] = [tuple(pair) for pair in offspring[\"individual\"]]\n",
    "    \n",
    "    data = [ind['individual'] for ind in data[\"new_offsprings\"]]\n",
    "\n",
    "    # Now it's a list of dicts, each with a list of tuples\n",
    "    # print(data)\n",
    "    return data\n",
    "\n",
    "def crossover(parent1, parent2, rate):\n",
    "    if random.random() > rate:\n",
    "        return parent1[:], parent2[:]\n",
    "    size = len(parent1)\n",
    "    message = smart_crossover_chain.invoke({'parent1':parent1, 'parent2': parent2})\n",
    "    print(message)\n",
    "    match = re.search(r'```json\\s*(.*?)\\s*```', message.content, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1)\n",
    "\n",
    "        # Step 2: Replace tuple-style parentheses with list-style brackets\n",
    "        json_str = json_str.replace(\"(\", \"[\").replace(\")\", \"]\")\n",
    "\n",
    "        # Step 3: Parse the cleaned string\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            print(\"Extracted Data:\")\n",
    "            # print(json.dumps(data, indent=2))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON parsing failed:\", e)\n",
    "    else:\n",
    "        print(\"No JSON block found.\")\n",
    "\n",
    "    # After loading the data using json.loads(...)\n",
    "    # Convert the inner lists to tuples\n",
    "\n",
    "    for offspring in data[\"new_offsprings\"]:\n",
    "        offspring[\"individual\"] = [tuple(pair) for pair in offspring[\"individual\"]]\n",
    "    # choose crossover points for order crossover\n",
    "    child1 = data[\"new_offsprings\"][0]['individual']\n",
    "    child2 = data[\"new_offsprings\"][1]['individual']\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual, rate):\n",
    "    if random.random() > rate:\n",
    "        return individual\n",
    "    size = len(individual)\n",
    "    start = size // 2\n",
    "    # select two positions in second half and swap genes\n",
    "    i, j = random.sample(range(start, size), 2)\n",
    "    ind = individual[:]\n",
    "    ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "\n",
    "def run_ga(pop_size, cx_rate, mut_rate, generations, tour_size, callback):\n",
    "    pop = generate_initial_population(pop_size)\n",
    "    best_hist = []\n",
    "    best_ind = None\n",
    "    best_fit = float('inf')\n",
    "    for gen in range(generations):\n",
    "        # evaluate\n",
    "        fits = [fitness(ind) for ind in pop]\n",
    "        best_gen_val = min(fits)\n",
    "        # record best\n",
    "        min_idx = int(np.argmin(fits))\n",
    "        if fits[min_idx] < best_fit:\n",
    "            best_fit = fits[min_idx]\n",
    "            best_ind = pop[min_idx][:]\n",
    "        best_hist.append(best_fit)\n",
    "        # selection\n",
    "        sel = tournament_selection(pop, fits, tour_size)\n",
    "        # generate next\n",
    "        # nxt = []\n",
    "        # for i in range(0, pop_size, 2):\n",
    "        #     p1 = sel[i]\n",
    "        #     p2 = sel[(i+1) % pop_size]\n",
    "        #     c1, c2 = crossover(p1, p2, cx_rate)\n",
    "        #     nxt.append(mutate(c1, mut_rate))\n",
    "        #     if len(nxt) < pop_size:\n",
    "        #         nxt.append(mutate(c2, mut_rate))\n",
    "        # pop = sel + nxt\n",
    "        new_offspring = smart_crossover(sel, cx_rate, pop_size)\n",
    "        new_offspring = [mutate(ind, mut_rate) for ind in new_offspring]\n",
    "        pop = pop_eval(new_offspring, gene_size=len(products))\n",
    "        pop = sel + new_offspring\n",
    "\n",
    "        if callback:\n",
    "            callback(gen, best_gen_val)\n",
    "\n",
    "    return best_ind, best_fit, best_hist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Hyperparameter tuning grid\n",
    "    random.seed = 42\n",
    "    pop_sizes = [50]\n",
    "    cx_rates = [0.9]\n",
    "    mut_rates = [0.05]\n",
    "    gens = [4]\n",
    "    tour_size = 3\n",
    "\n",
    "    best_overall = None\n",
    "    best_params = None\n",
    "    best_value = float('inf')\n",
    "    best_history = None\n",
    "\n",
    "    for ps in pop_sizes:\n",
    "        for mr in mut_rates:\n",
    "            for cr in cx_rates:\n",
    "                for g in gens:\n",
    "                    live_plot = LivePlot()\n",
    "                    ind, val, hist = run_ga(ps,cr, mr, g, tour_size, live_plot)\n",
    "                    # print(f\"Tested PS={ps}, CX={cr}, MU={mr}, GEN={g}: BestDist={val:.2f}\")\n",
    "                    if val < best_value:\n",
    "                        best_value = val\n",
    "                        best_overall = ind\n",
    "                        best_params = {'pop_size': ps, 'mut_rate': mr, 'generations': g}\n",
    "                        best_history = hist\n",
    "\n",
    "    # Final report\n",
    "    print(\"\\n=== Best Solution Found ===\")\n",
    "    print(f\"Method: Genetic Algorithm\")\n",
    "    print(f\"Hyperparameters: {best_params}\")\n",
    "    print(f\"Total Distance: {best_value:.2f}\")\n",
    "    print(\"Route (product -> location):\")\n",
    "    for p, l in best_overall:\n",
    "        print(f\"  {p} -> {l}\")\n",
    "    # Convergence plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(best_history, marker='o', linestyle='-')\n",
    "    plt.title(\"GA Convergence: Best Distance per Generation\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_initial_population(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pi[q_pi!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b700e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p,l in best_overall:\n",
    "    if(rp[p]<=q_pi.loc[p,l]):\n",
    "        pass\n",
    "        # print(f\"Product {p} can be picked from location {l} with sufficient quantity.\")\n",
    "    else:\n",
    "        print(rp[p],q_pi.loc[p,l])\n",
    "        print(f\"Product {p} cannot be picked from location {l} due to insufficient quantity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472dd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3134fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness(best_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Hyperparameter tuning grid\n",
    "    pop_sizes = [20]\n",
    "    # cx_rates = [0.6, 0.9]\n",
    "    mut_rates = [0.01]\n",
    "    gens = [20]\n",
    "    tour_size = 3\n",
    "\n",
    "    best_overall = None\n",
    "    best_params = None\n",
    "    best_value = float('inf')\n",
    "    best_history = None\n",
    "\n",
    "    for ps in pop_sizes:\n",
    "        for mr in mut_rates:\n",
    "            for g in gens:\n",
    "                ind, val, hist = run_ga(ps, mr, g, tour_size)\n",
    "                # print(f\"Tested PS={ps}, CX={cr}, MU={mr}, GEN={g}: BestDist={val:.2f}\")\n",
    "                if val < best_value:\n",
    "                    best_value = val\n",
    "                    best_overall = ind\n",
    "                    best_params = {'pop_size': ps, 'mut_rate': mr, 'generations': g}\n",
    "                    best_history = hist\n",
    "\n",
    "    # Final report\n",
    "    print(\"\\n=== Best Solution Found ===\")\n",
    "    print(f\"Method: Genetic Algorithm\")\n",
    "    print(f\"Hyperparameters: {best_params}\")\n",
    "    print(f\"Total Distance: {best_value:.2f}\")\n",
    "    print(\"Route (product -> location):\")\n",
    "    for p, l in best_overall:\n",
    "        print(f\"  {p} -> {l}\")\n",
    "    # Convergence plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(best_history, marker='o', linestyle='-')\n",
    "    plt.title(\"GA Convergence: Best Distance per Generation\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p,l in best_overall:\n",
    "    if(rp[p]<=q_pi.loc[p,l]):\n",
    "        pass\n",
    "        # print(f\"Product {p} can be picked from location {l} with sufficient quantity.\")\n",
    "    else:\n",
    "        print(rp[p],q_pi.loc[p,l])\n",
    "        print(f\"Product {p} cannot be picked from location {l} due to insufficient quantity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcbe6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, l in best_overall:\n",
    "        print(f\"  {p} -> {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1fc27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume the following variables are already defined in the environment:\n",
    "# q_pi: pandas.DataFrame, index=product IDs, columns=location IDs, available quantities\n",
    "# rp: dict, required quantities per product\n",
    "# distance_matrix: pandas.DataFrame, distances between locations\n",
    "# products: list of product IDs\n",
    "# locations: list of location IDs\n",
    "# location_start: starting/ending location ID\n",
    "\n",
    "def generate_initial_population(pop_size):\n",
    "    population = []\n",
    "    for _ in range(pop_size):\n",
    "        # assign each product to a valid location\n",
    "        loc_choice = {}\n",
    "        for p in products:\n",
    "            # only pick locations that have enough quantity\n",
    "            valid_locs = []\n",
    "            for l in locations:\n",
    "                x = q_pi.loc[p, l]\n",
    "                x = float(x)\n",
    "                if x < rp[p]:\n",
    "                    valid_locs.append(l)\n",
    "            if not valid_locs:\n",
    "                valid_locs = locations[:]  # fallback if none satisfy\n",
    "            loc_choice[p] = random.choice(valid_locs)\n",
    "        # create a random route order of products\n",
    "        prod_order = products[:]\n",
    "        random.shuffle(prod_order)\n",
    "        # individual is list of (product, location) in visit order\n",
    "        individual = [(p, loc_choice[p]) for p in prod_order]\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "def fitness(individual):\n",
    "    # sum distances along the route including return to start\n",
    "    total = 0.0\n",
    "    # from start to first\n",
    "    first_loc = individual[0][1]\n",
    "    total += distance_matrix.loc[location_start, first_loc]\n",
    "    # between consecutive\n",
    "    for i in range(len(individual)-1):\n",
    "        l1 = individual[i][1]\n",
    "        l2 = individual[i+1][1]\n",
    "        total += distance_matrix.loc[l1, l2]\n",
    "    # last back to start\n",
    "    last_loc = individual[-1][1]\n",
    "    total += distance_matrix.loc[last_loc, location_start]\n",
    "    # no feasibility penalty because we only chose valid locations\n",
    "    return total\n",
    "\n",
    "def tournament_selection(pop, fitnesses, k):\n",
    "    selected = []\n",
    "    pop_size = len(pop)\n",
    "    for _ in range(pop_size):\n",
    "        aspirants = random.sample(range(pop_size), k)\n",
    "        best = min(aspirants, key=lambda i: fitnesses[i])\n",
    "        selected.append(pop[best])\n",
    "    return selected\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, rate):\n",
    "    if random.random() > rate:\n",
    "        return parent1[:], parent2[:]\n",
    "    size = len(parent1)\n",
    "    # choose crossover points for order crossover\n",
    "    a, b = sorted(random.sample(range(size), 2))\n",
    "    # child1\n",
    "    segment1 = parent1[a:b]\n",
    "    leftover1 = [gene for gene in parent2 if gene[0] not in [g[0] for g in segment1]]\n",
    "    child1 = leftover1[:a] + segment1 + leftover1[a:]\n",
    "    # child2\n",
    "    segment2 = parent2[a:b]\n",
    "    leftover2 = [gene for gene in parent1 if gene[0] not in [g[0] for g in segment2]]\n",
    "    child2 = leftover2[:a] + segment2 + leftover2[a:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual, rate):\n",
    "    if random.random() > rate:\n",
    "        return individual\n",
    "    size = len(individual)\n",
    "    start = size // 2\n",
    "    # select two positions in second half and swap genes\n",
    "    i, j = random.sample(range(start, size), 2)\n",
    "    ind = individual[:]\n",
    "    ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "def run_ga(pop_size, mut_rate, generations, tour_size):\n",
    "    pop = generate_initial_population(pop_size)\n",
    "    best_hist = []\n",
    "    best_ind = None\n",
    "    best_fit = float('inf')\n",
    "    for gen in range(generations):\n",
    "        # evaluate\n",
    "        fits = [fitness(ind) for ind in pop]\n",
    "        # record best\n",
    "        min_idx = int(np.argmin(fits))\n",
    "        if fits[min_idx] < best_fit:\n",
    "            best_fit = fits[min_idx]\n",
    "            best_ind = pop[min_idx][:]\n",
    "        best_hist.append(best_fit)\n",
    "        # selection\n",
    "        sel = tournament_selection(pop, fits, tour_size)\n",
    "        # generate next\n",
    "        nxt = []\n",
    "        for i in range(0, pop_size, 2):\n",
    "            p1 = sel[i]\n",
    "            p2 = sel[(i+1) % pop_size]\n",
    "            c1, c2 = crossover(p1, p2, cx_rate)\n",
    "            nxt.append(mutate(c1, mut_rate))\n",
    "            if len(nxt) < pop_size:\n",
    "                nxt.append(mutate(c2, mut_rate))\n",
    "        pop = sel\n",
    "    return best_ind, best_fit, best_hist\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Hyperparameter tuning grid\n",
    "    pop_sizes = [10]\n",
    "    # cx_rates = [0.6, 0.9]\n",
    "    mut_rates = [0.01]\n",
    "    gens = [20]\n",
    "    tour_size = 3\n",
    "\n",
    "    best_overall = None\n",
    "    best_params = None\n",
    "    best_value = float('inf')\n",
    "    best_history = None\n",
    "\n",
    "    for ps in pop_sizes:\n",
    "        for mr in mut_rates:\n",
    "            for g in gens:\n",
    "                ind, val, hist = run_ga(ps, mr, g, tour_size)\n",
    "                # print(f\"Tested PS={ps}, CX={cr}, MU={mr}, GEN={g}: BestDist={val:.2f}\")\n",
    "                if val < best_value:\n",
    "                    best_value = val\n",
    "                    best_overall = ind\n",
    "                    best_params = {'pop_size': ps, 'mut_rate': mr, 'generations': g}\n",
    "                    best_history = hist\n",
    "\n",
    "    # Final report\n",
    "    print(\"\\n=== Best Solution Found ===\")\n",
    "    print(f\"Method: Genetic Algorithm\")\n",
    "    print(f\"Hyperparameters: {best_params}\")\n",
    "    print(f\"Total Distance: {best_value:.2f}\")\n",
    "    print(\"Route (product -> location):\")\n",
    "    for p, l in best_overall:\n",
    "        print(f\"  {p} -> {l}\")\n",
    "    # Convergence plot\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(best_history, marker='o', linestyle='-')\n",
    "    plt.title(\"GA Convergence: Best Distance per Generation\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ab4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Best Solution Found ===\")\n",
    "print(f\"Method: Genetic Algorithm\")\n",
    "print(f\"Hyperparameters: {best_params}\")\n",
    "print(f\"Total Distance: {best_value:.2f}\")\n",
    "print(\"Route (product -> location):\")\n",
    "for p, l in best_overall:\n",
    "    print(f\"  {p} -> {l}\")\n",
    "# Convergence plot\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(best_history, marker='o', linestyle='-')\n",
    "plt.title(\"GA Convergence: Best Distance per Generation\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32390a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2914d37d",
   "metadata": {},
   "source": [
    "# Data preprocessing agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a55a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing_prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a data preprocessing expert for operations research models.\n",
    "\n",
    "You will be given:\n",
    "- A description of available raw data\n",
    "{data_description}\n",
    "- A problem description\n",
    "{problem}\n",
    "- A formulation (objective, constraints, variables)\n",
    "{formulation}\n",
    "\n",
    "Your task is to:\n",
    "1. Identify what structured data is required from the raw data for the OR model\n",
    "2. Plan how to extract and preprocess that data\n",
    "3. Write a Python preprocessing function that returns the cleaned and structured data (e.g., DataFrames, dictionaries, arrays)\n",
    "4. Provide a detailed description of what this preprocessed data contains and how it maps to the OR formulation\n",
    "\n",
    "Respond in strict JSON format with the following keys:\n",
    "- `function`: A Python function named `preprocess_data(raw_data: dict) -> dict`\n",
    "- `data_description`: Text explaining each component of the returned preprocessed data, and how it connects to the model\n",
    "\n",
    "Do NOT include any extra explanations outside the JSON. Just output the JSON object.\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4.1\")\n",
    "data_preprocessing_chain = data_preprocessing_prompt| llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = \"\"\"\n",
    " random_storage: dataframe\n",
    " columns:\n",
    " originalLocation (location Id e.g. \"A-11-11\")\n",
    " col_1_label (product id)\n",
    " col_1_qty (quanity of product with product ID in col_1_label)\n",
    " similarly col_2_label, col_2_qty to col_18_label, col_18_qty\n",
    "\n",
    " distance_matrix: dataframe \n",
    " row & columns with location id\n",
    " and value in cell is distance between those locations\n",
    "\n",
    " Customer_Order:\n",
    " \n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87472e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing_chain.invoke({\n",
    "    \"data_description\":data_description,\n",
    "    \"problem\":problem,\n",
    "    \"formulation\":formulation\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79526c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
